<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>STRIDE threat modeling on Kubernetes pt.5/6: Denial of service | Maxgio's blog</title><meta name=keywords content="kubernetes,security"><meta name=description content="I&rsquo;m back after a long time with the fifth episode of this mini-series about STRIDE threat modeling in Kubernetes. In the previous one we talked about Information disclosure. This part is about the D that stands for Denial Of Service.
DOS is the attempt to making a resource unavailable. For instance, a Kubernetes dashboard is left exposed on the Internet, allowing anyone to deploy containers on your company&rsquo;s infrastructure to mine cryptocurrency and starve your legitimate applications of CPU (really happened - thanks Peter)."><meta name=author content><link rel=canonical href=https://blog.maxgio.me/posts/k8s-stride-05-denial-of-service/><link crossorigin=anonymous href=/assets/css/stylesheet.min.149ea7cdaa83f0ab31471ced9e0495af0272de908dd4a38e5c229d8b0579a758.css integrity="sha256-FJ6nzaqD8KsxRxztngSVrwJy3pCN1KOOXCKdiwV5p1g=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://blog.maxgio.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.maxgio.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.maxgio.me/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.maxgio.me/apple-touch-icon.png><link rel=mask-icon href=https://blog.maxgio.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','G-7DN0LVS78Q','auto');ga('send','pageview');}</script><meta property="og:title" content="STRIDE threat modeling on Kubernetes pt.5/6: Denial of service"><meta property="og:description" content="I&rsquo;m back after a long time with the fifth episode of this mini-series about STRIDE threat modeling in Kubernetes. In the previous one we talked about Information disclosure. This part is about the D that stands for Denial Of Service.
DOS is the attempt to making a resource unavailable. For instance, a Kubernetes dashboard is left exposed on the Internet, allowing anyone to deploy containers on your company&rsquo;s infrastructure to mine cryptocurrency and starve your legitimate applications of CPU (really happened - thanks Peter)."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.maxgio.me/posts/k8s-stride-05-denial-of-service/"><meta property="og:image" content="https://blog.maxgio.me/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-09-07T18:36:15+02:00"><meta property="article:modified_time" content="2020-09-07T18:36:15+02:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.maxgio.me/papermod-cover.png"><meta name=twitter:title content="STRIDE threat modeling on Kubernetes pt.5/6: Denial of service"><meta name=twitter:description content="I&rsquo;m back after a long time with the fifth episode of this mini-series about STRIDE threat modeling in Kubernetes. In the previous one we talked about Information disclosure. This part is about the D that stands for Denial Of Service.
DOS is the attempt to making a resource unavailable. For instance, a Kubernetes dashboard is left exposed on the Internet, allowing anyone to deploy containers on your company&rsquo;s infrastructure to mine cryptocurrency and starve your legitimate applications of CPU (really happened - thanks Peter)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.maxgio.me/posts/"},{"@type":"ListItem","position":2,"name":"STRIDE threat modeling on Kubernetes pt.5/6: Denial of service","item":"https://blog.maxgio.me/posts/k8s-stride-05-denial-of-service/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"STRIDE threat modeling on Kubernetes pt.5/6: Denial of service","name":"STRIDE threat modeling on Kubernetes pt.5\/6: Denial of service","description":"I\u0026rsquo;m back after a long time with the fifth episode of this mini-series about STRIDE threat modeling in Kubernetes. In the previous one we talked about Information disclosure. This part is about the D that stands for Denial Of Service.\nDOS is the attempt to making a resource unavailable. For instance, a Kubernetes dashboard is left exposed on the Internet, allowing anyone to deploy containers on your company\u0026rsquo;s infrastructure to mine cryptocurrency and starve your legitimate applications of CPU (really happened - thanks Peter).","keywords":["kubernetes","security"],"articleBody":"I’m back after a long time with the fifth episode of this mini-series about STRIDE threat modeling in Kubernetes. In the previous one we talked about Information disclosure. This part is about the D that stands for Denial Of Service.\nDOS is the attempt to making a resource unavailable. For instance, a Kubernetes dashboard is left exposed on the Internet, allowing anyone to deploy containers on your company’s infrastructure to mine cryptocurrency and starve your legitimate applications of CPU (really happened - thanks Peter).\nTherefore, an induced lack of resources is what generally leads to unavailability.\nSo, how we can do prevention? We can do it with:\n Increased Availability Resource isolation Resource monitoring Moreover, vulnerability-specific patches  Now let’s jump into Kubernetes world and think about splitting up the different layers on which to guarantee availability: Nodes Network Control plane Workload\nAs the availability can be increased on all resources, I’ll sum up briefly what we can do.\nMaster nodes  Deploy multiple master nodes to provide HA on the control plane (for instance to protect from direct attacks to the API server); Deploy on multiple datacenters (to protect from attacks on the network to a particular datacenter).  Worker nodes   Deploy on multiple datacenters (to protect from attacks on the network to a particular datacenter);\n  Configure resource limits per namespace by using ResourceQuotas for:\n CPU and memory; Storage (PVC per StorageClass); Object count; Extended resources (only limit);    Configure resource limits per container;\n can also be useful for scheduling purposes with Pod Priority, and can be able to define the workload’s Quality of Service; use LimitRanges to set resource defaults;    Configure out of resource handling to reclaim resources by notifying under pressure nodes to the kubelet;\n  Configure Cluster Autoscaler to gain availability based on your workload.\n  Workload  Configure Horizontal Pod Autoscaler; Configure correct resources limits other than requests; Configure Vertical Pod Autoscaler or addon-resizer; you can also leverage the VPA in Off mode in order to get only recommendations for setting appropriate resources for your workload; Define Pod-to-Pod and Pod-to-external Network Policies; Configure mutual TLS and proper API authentication mechanism.  API server  Configure high availability; Configure monitoring and alerting on requests and Audit; Isolate: do not expose the endpoint on Internet, for instance syn flood attacks could be in place.  etcd  Configure HA; Configure monitoring and alerting on requests; Isolate: so that only the control plane members can access it; As a plus, configure dedicated cluster, since etcd is one of the main bottlenecks and to provide resilience from the other control plane components (e.g. if they are compromised).  Network  Configure rate limiting at Ingress Controller level to limit connections and requests per seconds/minute per IP (for example with NGINX ingress controller); Deny source IPs with Network policies.  Then, other than following all the best practices there could also be vulnerabilities on components that we generally consider already secured; so let’s sum up a couple of them.\nKnown vulnerabilities CVE-2019–9512: Ping Flood with HTTP/2 The attacker hammers the HTTP/2 listener with a continuous flow of ping requests. To respond, the recipient start queuing the responses, leading to growing queues and then allocating more memory and CPU.\nCVE-2019–9514: Reset Flood with HTTP/2 The attacker can open several streams to the server and sending invalid data through them. Having received invalid data, the server sends HTTP/2 RST_STREAM frames to the attacker to cancel the “invalid” connection.\nWith lots of RST_STREAM responses, they start to queue. As the queue gets more massive, more and more CPU and memory get allocated to the application until it eventually crashes.\nKubernetes has released the required patches to mitigate the issues as mentioned above. The new versions were built using the patched versions of Go so that the required fixed are applied to the net/http library.\nFixed versions:\n Kubernetes v1.15.3 - go1.12.9 Kubernetes v1.14.6 - go1.12. Kubernetes v1.13.10 - go1.11.13  CVE-2020–8557: Node disk DOS The /etc/hosts file mounted in a pod by kubelet is not included by the kubelet eviction manager when calculating ephemeral storage usage by a pod. If a pod writes a large amount of data to the /etc/hosts file, it could fill the storage space of the node. Affected versions:\n kubelet v1.18.0–1.18.5 kubelet v1.17.0–1.17.8 kubelet  Fixed Versions:\n kubelet master - fixed by #92916 kubelet v1.18.6 - fixed by #92921 kubelet v1.17.9 - fixed by #92923 kubelet v1.16.13 - fixed by #92924  Prior to upgrading, this vulnerability can be mitigated by using PodSecurityPolicies or other admission webhooks to force containers to drop CAP_DAC_OVERRIDE or to prohibit privilege escalation and running as root. Consider anyway that these measures may break existing workloads that rely upon these privileges to function properly.\nCVE-2020–8551: Kubelet DoS via API The kubelet has been found to be vulnerable to a denial of service attack via kubelet API, including the unauthenticated HTTP read-only API typically served on port 10255, and the authenticated HTTPS API typically served on port 10250.\nAffected Versions:\n kubelet v1.17.0 - v1.17.2 kubelet v1.16.0 - v1.16.6 kubelet v1.15.0 - v1.15.9  Fixed Versions\n kubelet v1.17.3 kubelet v1.16.7 kubelet v1.15.10  In order to mitigate this issue limit access to the kubelet API or patch the kubelet.\nCVE-2020–8552: Kubernetes API Server OOM The API server has been found to be vulnerable to a denial of service attack via authorized API requests.\nAffected Versions:\n kube-apiserver v1.17.0 - v1.17.2 kube-apiserver v1.16.0 - v1.16.6 kube-apiserver  Fixed Versions:\n kube-apiserver v1.17.3 kube-apiserver v1.16.7 kube-apiserver v1.15.10  Prior to upgrading, this vulnerability can be mitigated by preventing unauthenticated or unauthorized access to all apis and by ensuring that the API server automatically restarts if it OOMs.\nCVE-2019–1002100: Kubernetes API Server JSON-patch parsing Users that are authorized to make patch requests to the Kubernetes API server can send a specially crafted patch of type json-patch (e.g. kubectl patch - type json or Content-Type: application/json-patch+json) that consumes excessive resources while processing, causing a denial of service on the API server.\nAffected versions:\n Kubernetes v1.0.x-1.10.x Kubernetes v1.11.0–1.11.7 Kubernetes v1.12.0–1.12.5 Kubernetes v1.13.0–1.13.3  Fixed Versions:\n Kubernetes v1.11.8 Kubernetes v1.12.6 Kubernetes v1.13.4  Prior to upgrading, this vulnerability can be mitigated by removing patch permissions from untrusted users.\nCVE-2019–11253: Kubernetes API Server JSON/YAML parsing This is a vulnerability in the API server, allowing authorized users sending malicious YAML or JSON payloads to cause kube-apiserver to consume excessive CPU or memory, potentially crashing and becoming unavailable.\nPrior to v1.14.0, default RBAC policy authorized anonymous users to submit requests that could trigger this vulnerability.\nClusters upgraded from a version prior to v1.14.0 keep the more permissive policy by default for backwards compatibility. Here you can find the more restrictive RBAC rules that can mitigate the issue.\nAffected versions:\n Kubernetes v1.0.0–1.12.x Kubernetes v1.13.0–1.13.11 Kubernetes v1.14.0–1.14.7 Kubernetes v1.15.0–1.15.4 Kubernetes v1.16.0–1.16.1  Fixed Versions:\n Kubernetes v1.13.12 Kubernetes v1.14.8 Kubernetes v1.15.5 Kubernetes v1.16.2  Consider that if you are running a version prior to v1.14.0, in addition to installing the restrictive policy, turn off autoupdate for the applied ClusterRoleBinding so your changes aren’t replaced on an API server restart.\nOn the related Github issue you can find more details that I didn’t insert here for conciseness.\nConclusion So, that’s all folks! If we followed all these rules and applied the released patches that’s a good starting point for prevention and can also help on detection and remediation.\nStay tuned for the next and final episode about the E of STRIDE: Escalation of privileges!\n","wordCount":"1220","inLanguage":"en","datePublished":"2020-09-07T18:36:15+02:00","dateModified":"2020-09-07T18:36:15+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.maxgio.me/posts/k8s-stride-05-denial-of-service/"},"publisher":{"@type":"Organization","name":"Maxgio's blog","logo":{"@type":"ImageObject","url":"https://blog.maxgio.me/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://blog.maxgio.me/ accesskey=h title="Maxgio's blog (Alt + H)">Maxgio's blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://blog.maxgio.me/posts title=Posts><span>Posts</span></a></li><li><a href=https://blog.maxgio.me/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://blog.maxgio.me/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/maxgio92 title=Github><span>Github</span></a></li><li><a href=https://hachyderm.io/@maxgio92 title=Mastodon><span>Mastodon</span></a></li><li><a href=https://twitter.com/maxgio92 title=Twitter><span>Twitter</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.maxgio.me/>Home</a>&nbsp;»&nbsp;<a href=https://blog.maxgio.me/posts/>Posts</a></div><h1 class=post-title>STRIDE threat modeling on Kubernetes pt.5/6: Denial of service</h1><div class=post-meta><span title="2020-09-07 18:36:15 +0200 +0200">September 7, 2020</span>&nbsp;·&nbsp;6 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#master-nodes aria-label="Master nodes">Master nodes</a></li><li><a href=#worker-nodes aria-label="Worker nodes">Worker nodes</a></li><li><a href=#workload aria-label=Workload>Workload</a></li><li><a href=#api-server aria-label="API server">API server</a></li><li><a href=#etcd aria-label=etcd>etcd</a></li><li><a href=#network aria-label=Network>Network</a></li><li><a href=#known-vulnerabilities aria-label="Known vulnerabilities">Known vulnerabilities</a><ul><li><a href=#cve-20199512httpscvemitreorgcgi-bincvenamecginamecve-2019-9512-ping-flood-with-http2 aria-label="CVE-2019–9512: Ping Flood with HTTP/2"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9512">CVE-2019–9512</a>: Ping Flood with HTTP/2</a></li><li><a href=#cve-20199514httpscvemitreorgcgi-bincvenamecginamecve-2019-9514-reset-flood-with-http2 aria-label="CVE-2019–9514: Reset Flood with HTTP/2"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9514">CVE-2019–9514</a>: Reset Flood with HTTP/2</a></li><li><a href=#cve-20208557httpscvemitreorgcgi-bincvenamecginamecve-2020-8557-node-disk-dos aria-label="CVE-2020–8557: Node disk DOS"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8557">CVE-2020–8557</a>: Node disk DOS</a></li><li><a href=#cve-20208551httpscvemitreorgcgi-bincvenamecginamecve-2020-8551-kubelet-dos-via-api aria-label="CVE-2020–8551: Kubelet DoS via API"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8551">CVE-2020–8551</a>: Kubelet DoS via API</a></li><li><a href=#cve-20208552httpscvemitreorgcgi-bincvenamecginamecve-2020-8552-kubernetes-api-server-oom aria-label="CVE-2020–8552: Kubernetes API Server OOM"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8552">CVE-2020–8552</a>: Kubernetes API Server OOM</a></li><li><a href=#cve-20191002100httpscvemitreorgcgi-bincvenamecginamecve-2019-1002100-kubernetes-api-server-json-patch-parsing aria-label="CVE-2019–1002100: Kubernetes API Server JSON-patch parsing"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1002100">CVE-2019–1002100</a>: Kubernetes API Server JSON-patch parsing</a></li><li><a href=#cve-201911253httpscvemitreorgcgi-bincvenamecginamecve-2019-11253-kubernetes-api-server-jsonyaml-parsing aria-label="CVE-2019–11253: Kubernetes API Server JSON/YAML parsing"><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11253">CVE-2019–11253</a>: Kubernetes API Server JSON/YAML parsing</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></div></details></div><div class=post-content><p>I&rsquo;m back after a long time with the fifth episode of this mini-series about STRIDE threat modeling in Kubernetes.
In the previous one we talked about Information disclosure. This part is about the D that stands for <strong>Denial Of Service</strong>.</p><p>DOS is the attempt to making a resource unavailable.
For instance, a Kubernetes dashboard is left exposed on the Internet, allowing anyone to deploy containers on your company&rsquo;s infrastructure to mine cryptocurrency and starve your legitimate applications of CPU (<a href=https://redlock.io/blog/cryptojacking-tesla>really happened</a> - thanks <a href=https://dev.to/petermbenjamin>Peter</a>).</p><p>Therefore, an induced lack of resources is what generally leads to unavailability.</p><p>So, how we can do prevention?
We can do it with:</p><ul><li>Increased Availability</li><li>Resource isolation</li><li>Resource monitoring</li><li>Moreover, vulnerability-specific patches</li></ul><p>Now let&rsquo;s jump into Kubernetes world and think about splitting up the different layers on which to guarantee availability:
Nodes
Network
Control plane
Workload</p><p>As the availability can be increased on all resources, I&rsquo;ll sum up briefly what we can do.</p><h1 id=master-nodes>Master nodes<a hidden class=anchor aria-hidden=true href=#master-nodes>#</a></h1><ul><li>Deploy <a href=https://kubernetes.io/docs/tasks/administer-cluster/highly-available-master/>multiple master nodes</a> to provide HA on the control plane (for instance to protect from direct attacks to the API server);</li><li>Deploy on multiple datacenters (to protect from attacks on the network to a particular datacenter).</li></ul><h1 id=worker-nodes>Worker nodes<a hidden class=anchor aria-hidden=true href=#worker-nodes>#</a></h1><ul><li><p>Deploy on multiple datacenters (to protect from attacks on the network to a particular datacenter);</p></li><li><p>Configure resource limits per namespace by using <a href=https://kubernetes.io/docs/concepts/policy/resource-quotas/><code>ResourceQuotas</code></a> for:</p><ul><li>CPU and memory;</li><li>Storage (<code>PVC</code> per <code>StorageClass</code>);</li><li>Object count;</li><li>Extended resources (only limit);</li></ul></li><li><p>Configure <a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits>resource limits</a> per container;</p><ul><li>can also be useful for scheduling purposes with <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/>Pod Priority</a>, and can be able to define the workload&rsquo;s <a href=https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/>Quality of Service</a>;</li><li>use <a href=https://kubernetes.io/docs/concepts/policy/limit-range/><code>LimitRanges</code></a> to set resource defaults;</li></ul></li><li><p>Configure <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/>out of resource handling</a> to reclaim resources by notifying <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/#node-conditions>under pressure nodes</a> to the <code>kubelet</code>;</p></li><li><p>Configure <a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>Cluster Autoscaler</a> to gain availability based on your workload.</p></li></ul><h1 id=workload>Workload<a hidden class=anchor aria-hidden=true href=#workload>#</a></h1><ul><li>Configure <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>Horizontal Pod Autoscaler</a>;</li><li>Configure correct <a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>resources limits</a> other than requests;</li><li>Configure <a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler>Vertical Pod Autoscaler</a> or <a href=https://github.com/kubernetes/autoscaler/tree/master/addon-resizer>addon-resizer</a>; you can also leverage the VPA in <a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#quick-start><code>Off mode</code></a> in order to get only recommendations for setting appropriate resources for your workload;</li><li>Define Pod-to-Pod and Pod-to-external <a href=https://kubernetes.io/docs/concepts/services-networking/network-policies/>Network Policies</a>;</li><li>Configure mutual TLS and proper API authentication mechanism.</li></ul><h1 id=api-server>API server<a hidden class=anchor aria-hidden=true href=#api-server>#</a></h1><ul><li>Configure <a href=https://kubernetes.io/docs/tasks/administer-cluster/highly-available-master/>high availability</a>;</li><li>Configure <a href=https://sysdig.com/blog/monitor-kubernetes-api-server/>monitoring</a> and alerting on requests and <a href=https://kubernetes.io/docs/tasks/debug-application-cluster/audit/><code>Audit</code></a>;</li><li>Isolate: do not expose the endpoint on Internet, for instance <a href=https://en.wikipedia.org/wiki/SYN_flood>syn flood</a> attacks could be in place.</li></ul><h1 id=etcd>etcd<a hidden class=anchor aria-hidden=true href=#etcd>#</a></h1><ul><li>Configure <a href=https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#multi-node-etcd-cluster>HA</a>;</li><li>Configure <a href=https://sysdig.com/blog/monitor-etcd/>monitoring and alerting</a> on requests;</li><li><a href=https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#limiting-access-of-etcd-clusters>Isolate</a>: so that only the control plane members can access it;</li><li>As a plus, configure <a href=https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#starting-etcd-clusters>dedicated cluster</a>, since etcd is one of the main bottlenecks and to provide resilience from the other control plane components (e.g. if they are compromised).</li></ul><h1 id=network>Network<a hidden class=anchor aria-hidden=true href=#network>#</a></h1><ul><li>Configure rate limiting at Ingress Controller level to limit connections and requests per seconds/minute per IP (for example <a href=https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#rate-limiting>with NGINX ingress controller</a>);</li><li>Deny source IPs with Network policies.</li></ul><p>Then, other than following all the best practices there could also be vulnerabilities on components that we generally consider already secured; so let&rsquo;s sum up a couple of them.</p><h1 id=known-vulnerabilities>Known vulnerabilities<a hidden class=anchor aria-hidden=true href=#known-vulnerabilities>#</a></h1><h2 id=cve-20199512httpscvemitreorgcgi-bincvenamecginamecve-2019-9512-ping-flood-with-http2><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9512">CVE-2019–9512</a>: Ping Flood with HTTP/2<a hidden class=anchor aria-hidden=true href=#cve-20199512httpscvemitreorgcgi-bincvenamecginamecve-2019-9512-ping-flood-with-http2>#</a></h2><p>The attacker hammers the HTTP/2 listener with a continuous flow of ping requests. To respond, the recipient start queuing the responses, leading to growing queues and then allocating more memory and CPU.</p><h2 id=cve-20199514httpscvemitreorgcgi-bincvenamecginamecve-2019-9514-reset-flood-with-http2><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-9514">CVE-2019–9514</a>: Reset Flood with HTTP/2<a hidden class=anchor aria-hidden=true href=#cve-20199514httpscvemitreorgcgi-bincvenamecginamecve-2019-9514-reset-flood-with-http2>#</a></h2><p>The attacker can open several streams to the server and sending invalid data through them.
Having received invalid data, the server sends HTTP/2 <code>RST_STREAM</code> frames to the attacker to cancel the &ldquo;invalid&rdquo; connection.</p><p>With lots of <code>RST_STREAM</code> responses, they start to queue.
As the queue gets more massive, more and more CPU and memory get allocated to the application until it eventually crashes.</p><p>Kubernetes has released the required patches to mitigate the issues as mentioned above. The new versions were built using the patched versions of Go so that the required fixed are applied to the net/http library.</p><p>Fixed versions:</p><ul><li>Kubernetes v1.15.3 - go1.12.9</li><li>Kubernetes v1.14.6 - go1.12.</li><li>Kubernetes v1.13.10 - go1.11.13</li></ul><h2 id=cve-20208557httpscvemitreorgcgi-bincvenamecginamecve-2020-8557-node-disk-dos><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8557">CVE-2020–8557</a>: Node disk DOS<a hidden class=anchor aria-hidden=true href=#cve-20208557httpscvemitreorgcgi-bincvenamecginamecve-2020-8557-node-disk-dos>#</a></h2><p>The /etc/hosts file mounted in a pod by kubelet is not included by the kubelet eviction manager when <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/#with-imagefs-1>calculating ephemeral storage</a> usage by a pod. If a pod writes a large amount of data to the /etc/hosts file, it could fill the storage space of the node.
Affected versions:</p><ul><li>kubelet v1.18.0–1.18.5</li><li>kubelet v1.17.0–1.17.8</li><li>kubelet &lt; v1.16.13</li></ul><p>Fixed Versions:</p><ul><li>kubelet master - fixed by #92916</li><li>kubelet v1.18.6 - fixed by #92921</li><li>kubelet v1.17.9 - fixed by #92923</li><li>kubelet v1.16.13 - fixed by #92924</li></ul><p>Prior to upgrading, this vulnerability can be mitigated by using PodSecurityPolicies or other admission webhooks to force containers to drop <a href=https://man7.org/linux/man-pages/man7/capabilities.7.html><code>CAP_DAC_OVERRIDE</code></a> or to prohibit privilege escalation and running as root. </p><p>Consider anyway that these measures may break existing workloads that rely upon these privileges to function properly.</p><h2 id=cve-20208551httpscvemitreorgcgi-bincvenamecginamecve-2020-8551-kubelet-dos-via-api><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8551">CVE-2020–8551</a>: Kubelet DoS via API<a hidden class=anchor aria-hidden=true href=#cve-20208551httpscvemitreorgcgi-bincvenamecginamecve-2020-8551-kubelet-dos-via-api>#</a></h2><p>The <code>kubelet</code> has been found to be vulnerable to a denial of service attack via kubelet API, including the unauthenticated HTTP read-only API typically served on port 10255, and the authenticated HTTPS API typically served on port 10250.</p><p>Affected Versions:</p><ul><li>kubelet v1.17.0 - v1.17.2</li><li>kubelet v1.16.0 - v1.16.6</li><li>kubelet v1.15.0 - v1.15.9</li></ul><p>Fixed Versions</p><ul><li>kubelet v1.17.3</li><li>kubelet v1.16.7</li><li>kubelet v1.15.10</li></ul><p>In order to mitigate this issue <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/>limit access to the kubelet API</a> or patch the kubelet.</p><h2 id=cve-20208552httpscvemitreorgcgi-bincvenamecginamecve-2020-8552-kubernetes-api-server-oom><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-8552">CVE-2020–8552</a>: Kubernetes API Server OOM<a hidden class=anchor aria-hidden=true href=#cve-20208552httpscvemitreorgcgi-bincvenamecginamecve-2020-8552-kubernetes-api-server-oom>#</a></h2><p>The API server has been found to be vulnerable to a denial of service attack via authorized API requests.</p><p>Affected Versions:</p><ul><li>kube-apiserver v1.17.0 - v1.17.2</li><li>kube-apiserver v1.16.0 - v1.16.6</li><li>kube-apiserver &lt; v1.15.10</li></ul><p>Fixed Versions:</p><ul><li>kube-apiserver v1.17.3</li><li>kube-apiserver v1.16.7</li><li>kube-apiserver v1.15.10</li></ul><p>Prior to upgrading, this vulnerability can be mitigated by <a href=https://kubernetes.io/docs/concepts/security/controlling-access/>preventing unauthenticated or unauthorized access</a> to all apis and by ensuring that the API server automatically restarts if it OOMs.</p><h2 id=cve-20191002100httpscvemitreorgcgi-bincvenamecginamecve-2019-1002100-kubernetes-api-server-json-patch-parsing><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-1002100">CVE-2019–1002100</a>: Kubernetes API Server JSON-patch parsing<a hidden class=anchor aria-hidden=true href=#cve-20191002100httpscvemitreorgcgi-bincvenamecginamecve-2019-1002100-kubernetes-api-server-json-patch-parsing>#</a></h2><p>Users that are authorized to make patch requests to the Kubernetes API server can send a specially crafted patch of type <a href=https://tools.ietf.org/html/rfc6902><code>json-patch</code></a> (e.g. <code>kubectl patch - type json</code> or <code>Content-Type: application/json-patch+json</code>) that consumes excessive resources while processing, causing a denial of service on the API server.</p><p>Affected versions:</p><ul><li>Kubernetes v1.0.x-1.10.x</li><li>Kubernetes v1.11.0–1.11.7</li><li>Kubernetes v1.12.0–1.12.5</li><li>Kubernetes v1.13.0–1.13.3</li></ul><p>Fixed Versions:</p><ul><li>Kubernetes v1.11.8</li><li>Kubernetes v1.12.6</li><li>Kubernetes v1.13.4</li></ul><p>Prior to upgrading, this vulnerability can be mitigated by removing patch permissions from untrusted users.</p><h2 id=cve-201911253httpscvemitreorgcgi-bincvenamecginamecve-2019-11253-kubernetes-api-server-jsonyaml-parsing><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-11253">CVE-2019–11253</a>: Kubernetes API Server JSON/YAML parsing<a hidden class=anchor aria-hidden=true href=#cve-201911253httpscvemitreorgcgi-bincvenamecginamecve-2019-11253-kubernetes-api-server-jsonyaml-parsing>#</a></h2><p>This is a vulnerability in the API server, allowing authorized users sending malicious YAML or JSON payloads to cause kube-apiserver to consume excessive CPU or memory, potentially crashing and becoming unavailable.</p><p>Prior to v1.14.0, default RBAC policy authorized anonymous users to submit requests that could trigger this vulnerability.</p><p>Clusters upgraded from a version prior to v1.14.0 keep the more permissive policy by default for backwards compatibility.
Here you can find the more restrictive RBAC rules that can mitigate the issue.</p><p>Affected versions:</p><ul><li>Kubernetes v1.0.0–1.12.x</li><li>Kubernetes v1.13.0–1.13.11</li><li>Kubernetes v1.14.0–1.14.7</li><li>Kubernetes v1.15.0–1.15.4</li><li>Kubernetes v1.16.0–1.16.1</li></ul><p>Fixed Versions:</p><ul><li>Kubernetes v1.13.12</li><li>Kubernetes v1.14.8</li><li>Kubernetes v1.15.5</li><li>Kubernetes v1.16.2</li></ul><p>Consider that if you are running a version prior to v1.14.0, in addition to installing the restrictive policy, turn off autoupdate for the applied ClusterRoleBinding so your changes aren&rsquo;t replaced on an API server restart.</p><p>On the related Github issue you can find more details that I didn&rsquo;t insert here for conciseness.</p><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>So, that&rsquo;s all folks! If we followed all these rules and applied the released patches that&rsquo;s a good starting point for prevention and can also help on detection and remediation.</p><p>Stay tuned for the next and final episode about the E of STRIDE: Escalation of privileges!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.maxgio.me/tags/kubernetes/>kubernetes</a></li><li><a href=https://blog.maxgio.me/tags/security/>security</a></li></ul><nav class=paginav><a class=prev href=https://blog.maxgio.me/posts/stride-threat-modeling-kubernetes-elevation-of-privileges/><span class=title>« Prev</span><br><span>STRIDE threat modeling on Kubernetes pt.6/6: Elevation of privilege</span></a>
<a class=next href=https://blog.maxgio.me/posts/k8s-stride-04-information-disclosure/><span class=title>Next »</span><br><span>STRIDE threat modeling on Kubernetes pt.4/6: Information disclosure</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share STRIDE threat modeling on Kubernetes pt.5/6: Denial of service on twitter" href="https://twitter.com/intent/tweet/?text=STRIDE%20threat%20modeling%20on%20Kubernetes%20pt.5%2f6%3a%20Denial%20of%20service&url=https%3a%2f%2fblog.maxgio.me%2fposts%2fk8s-stride-05-denial-of-service%2f&hashtags=kubernetes%2csecurity"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share STRIDE threat modeling on Kubernetes pt.5/6: Denial of service on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblog.maxgio.me%2fposts%2fk8s-stride-05-denial-of-service%2f&title=STRIDE%20threat%20modeling%20on%20Kubernetes%20pt.5%2f6%3a%20Denial%20of%20service&summary=STRIDE%20threat%20modeling%20on%20Kubernetes%20pt.5%2f6%3a%20Denial%20of%20service&source=https%3a%2f%2fblog.maxgio.me%2fposts%2fk8s-stride-05-denial-of-service%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://blog.maxgio.me/>Maxgio's blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerHTML='copy';function copyingDone(){copybutton.innerHTML='copied!';setTimeout(()=>{copybutton.innerHTML='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>