<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A journey into the Linux scheduler | Maxgio's blog</title><meta name=keywords content="linux,scheduler"><meta name=description content="Two years ago more or less I started my journey in Linux. I was scared at first and I didn&rsquo;t know where to start from. But then I decided to buy a book - and what a book! - in order to follow a path.
Along the way, I integrated the material with up-to-date documentation from kernel.org and source code. In the meantime, I started to learn C a bit so that I also could have played with what I was learning, step by step."><meta name=author content><link rel=canonical href=http://maxgio92.github.io/posts/linux-scheduler-journey/><link crossorigin=anonymous href=/assets/css/stylesheet.min.149ea7cdaa83f0ab31471ced9e0495af0272de908dd4a38e5c229d8b0579a758.css integrity="sha256-FJ6nzaqD8KsxRxztngSVrwJy3pCN1KOOXCKdiwV5p1g=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=http://maxgio92.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://maxgio92.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://maxgio92.github.io/favicon-32x32.png><link rel=apple-touch-icon href=http://maxgio92.github.io/apple-touch-icon.png><link rel=mask-icon href=http://maxgio92.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','G-7DN0LVS78Q','auto');ga('send','pageview');}</script><meta property="og:title" content="A journey into the Linux scheduler"><meta property="og:description" content="Two years ago more or less I started my journey in Linux. I was scared at first and I didn&rsquo;t know where to start from. But then I decided to buy a book - and what a book! - in order to follow a path.
Along the way, I integrated the material with up-to-date documentation from kernel.org and source code. In the meantime, I started to learn C a bit so that I also could have played with what I was learning, step by step."><meta property="og:type" content="article"><meta property="og:url" content="http://maxgio92.github.io/posts/linux-scheduler-journey/"><meta property="og:image" content="http://maxgio92.github.io/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-06-24T00:00:00+02:00"><meta property="article:modified_time" content="2022-06-24T00:00:00+02:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://maxgio92.github.io/papermod-cover.png"><meta name=twitter:title content="A journey into the Linux scheduler"><meta name=twitter:description content="Two years ago more or less I started my journey in Linux. I was scared at first and I didn&rsquo;t know where to start from. But then I decided to buy a book - and what a book! - in order to follow a path.
Along the way, I integrated the material with up-to-date documentation from kernel.org and source code. In the meantime, I started to learn C a bit so that I also could have played with what I was learning, step by step."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://maxgio92.github.io/posts/"},{"@type":"ListItem","position":2,"name":"A journey into the Linux scheduler","item":"http://maxgio92.github.io/posts/linux-scheduler-journey/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A journey into the Linux scheduler","name":"A journey into the Linux scheduler","description":"Two years ago more or less I started my journey in Linux. I was scared at first and I didn\u0026rsquo;t know where to start from. But then I decided to buy a book - and what a book! - in order to follow a path.\nAlong the way, I integrated the material with up-to-date documentation from kernel.org and source code. In the meantime, I started to learn C a bit so that I also could have played with what I was learning, step by step.","keywords":["linux","scheduler"],"articleBody":"Two years ago more or less I started my journey in Linux. I was scared at first and I didn’t know where to start from. But then I decided to buy a book - and what a book! - in order to follow a path.\nAlong the way, I integrated the material with up-to-date documentation from kernel.org and source code. In the meantime, I started to learn C a bit so that I also could have played with what I was learning, step by step.\nOne of the things I was fascinated by was how Linux is able to manage and let the CPU run thousands and thousands of processes each second. To give you an idea, right now, Linux on my laptop configured with an Intel i7-1185G7 CPU switched context 28,428 times in a second! That’s fantastic, isn’t it?\n$ perf stat -e sched:sched_switch --timeout 1000 Performance counter stats for 'system wide': 28,428 sched:sched_switch 1.001137885 seconds time elapsed During this journey inside Linux, I’ve written notes as it helps me to digest and re-process in my own way the informations I learn. Then I thought: “Maybe they’re useful to someone. Why not share them?”.\nSo here I am with with a blog.\n 1. Resource sharing is the key! Let’s dive into the Linux component which is responsible for doing such great work: the scheduler.\nIn order to do it, imagine what we would expect from an operating system. Let’s say that we’d want it to run tasks that we need to complete, providing the OS hardware resources. Tasks come of different natures but we can simply categorize them as CPU-intensive and interactive ones.\nSomething should provide the efficiency of task completion and responsiveness. Consider a typewriter that prints letters with 1s second of delay, it would be impossible to use! So, in a few words, I would like to request to the scheduler: “I want to execute this task and I want it’s completed when I need or to respond when I need”. The goal of a scheduler is to decide “what runs next” leading to have the best balance between the needings of the different natures of the tasks.\nAs Linux is a preemptive multitasking operating system, the completely fair scheduler (CFS) came to Linux, as the replacement of the O(1) scheduler from the 2.6.23, with the aim to guarantee the fairness of CPU owning by the tasks, and at the same time tailoring to a broad nature range of tasks. Although the algorithm complexity didn’t see an improvement, from O(1) to O(log N), the reduced latency removed issues when dealing with interactive tasks.\nAs a side note consider that the Linux scheduler is made of different scheduler classes (code), of which the CFS class is the highest-priority one. Another one is the real-time scheduler class, tailored as the name suggests for tasks that need responsiveness.\nInteractive tasks would run for small amounts of time but need to run quickly as events happen. CPU-intensive tasks don’t require to complete ASAP but require longer CPU time. Based on that, time accounting is what guarantees fairness in the Linux CFS scheduler as long as the task that runs for less time will run next.\nThis comes to the time accounting, so let’s start to dig into it!\n 2. Time accounting Linux CFS actually does not directly assign timeslices to tasks as the O(1) scheduler did, instead it measures execution time, in order to be flexible with respect to both interactive and processor-intensive tasks.\nThe runtime Remember, the fundamental rule in the Completely Fair Scheduler is: the task that ran less, will run next! Which is, each task should have its fair slice of processor time when it needs! For example, interactive tasks can run frequently but for less time than intensive ones, and still have their fair amount of CPU time.\nThe implementation is written in the update_curr() function, which is called periodically to account tasks for the CPU time they used in the last period (delta_exec).\nThe virtual runtime The execution time is further weighted to implement priority between tasks. This is done by the fair delta calculation. The more the weight, the more time the task will have.\nExample Let' do an example with timeslices: considering a single CPU, if every T time period two tasks A and B run respectively with a weight of 1 and 2, the allocated CPU time is obtained by multiplying T by the ratio of the weight to the sum of the weights of all running tasks:\nCPU_timeslice(A) = T * (1 / (1 + 2))). CPU_timeslice(B) = T * (2 / (1 + 2))). For each T time period, task A will run for 0.334~T and task B 0.667~T.\n This is what is calculated here.\n Implementation Coming to the actual implementation, the CFS class accounts tasks for their real execution time considering their weight, which is ensured by periodically measuring the runtime and multiplying it by the ratio weight/(base weight).\nruntime += runtime * (w / base w)). Which is exactly what is done in update_curr():\nstatic void update_curr(struct cfs_rq *cfs_rq) { struct sched_entity *curr = cfs_rq-curr; ... delta_exec = now - curr-exec_start; ... curr-vruntime += calc_delta_fair(delta_exec, curr); ... } And the result is the so-called virtual runtime (vruntime).\nAs the weight implementation depends on the nature of the schedule entities, let’s spend a couple of words about them.\n Indeed, the vruntime is a member of the sched_entity structure.\n Then, we’ll talk more about the runtime weight.\nThe schedule entities Until now we talked about tasks as the only schedulable entity but actually, tasks can be put into group of tasks, in order to treat a group equally to a single task, and have the group share the resources (I.e. CPU) between the entities of the group without afflicting the overall system. That’s the case of cgroups and why they’re there.\nAlso, task groups can be composed of other groups, and there is a root group. In the end, a running Linux is likely going to manage a hierarchy tree of schedule entities. So when a task should be accounted for time, also the parent group’s entity should be, and so on, until the root group entity is found.\n Consider that the sched_entity structure is the structure that tracks information about the scheduling, like the vruntime, and it refers to tasks or tasks group structures. As they track scheduling data, they are per-CPU structures. Instead, task_struct and task_group structures, are global.\n And this comes to the weight.\nThe weight We said before that the weight implementation depends on the nature of the entity. If the entity is a task the weight is represented by the niceness value (code). If it’s a task group, the weight is represented by the CPU shares value.\n In cgroup v2 the shares is named directly weight.\n In the end, the weight is what matters: in the case of tasks the niceness is converted to priority and then to weight (here). In the case of task groups the user-visible value is internally converted.\nFor the sake of simplicity let’s remember this: the groups are hierarchical, and a task is part of a task group. The bigger the depth of the hierarchy, the more the weight gets diluted. Adding a heavily weighted task to one child group is not going to afflict the overall tasks tree the same as it would do if it was part of the root group. This is because the task weight is relative to the group which the task is put into.\nEach entity, whether a task or a task group, is treated the same. The time accounting is applied to the currently locally running entity and recursively up through the hierarchy.\n In case of task groups, the weight is further scaled, but don’t worry, we’ll talk about it later.\n Update of the virtual runtime This virtual runtime is updated on the schedule entity that is currently running on the local CPU via update_curr() function, which is called:\n whenever a task becomes runnable, or whenever blocks become unrunnable, and periodically (every 1/CONFIG_HZ seconds) by the system timer interrupt handler.   As a detail, the virtual runtime value if the task is just forked, is initialized to a minimum value which depends on the runqueue load (cfs_rq-min_vruntime).\n And this leads to the next question: how this accounting is honored in the task selection in the scheduler in order to guarantee fairness of execution?\n 3. Task selection The schedule entities eligible to run (which is in a runnable state) are put in a run queue, which is implemented as a red black self-balancing binary tree that contains schedule entity structures ordered by vruntime.\nThe runqueues Runqueues are per-CPU structures and contain schedule entities and they have a pointer to the entity which is currently running on the related CPU. The schedule entities they refer to are related to the local CPU because the sched_entitys contain information about scheduling and thus are specific to a CPU. The vruntime is the binary tree key so the entity with the smallest vruntime is picked during a new schedule.\n Each scheduler class has its specific runqueue, which are part of the general runqueues. Anyway, let’s consider now only CFS runqueues.\n In turn, also each task group has a dedicated CFS runqueue, from the root task group through its child task groups. __pick_next_entity() picks the entity with the smallest virtual runtime, whether is an actual task or a group. If it’s a task group the search is repeated on its runqueue and so on, going through the hierarchy of runqueues until a real task is found to be run.\nEach runqueue keeps track of the schedule entities that are running/runnable on the local CPU.\nIn a nutshell  Tasks groups are global. Tasks also are global. Every task is part of a task group. There is one runqueue per task group per CPU. Runqueues are composed of schedule entities. Schedule entities reference tasks or task groups. Schedule entities are per CPU  Wrapping up the structures To make it more clear, let’s see a practical example. You can see below a diagram for a sample scenario where there are two tasks (p1 and p2), and two task groups (root task group and tg1, child of the root task group). And p1 is direct child of task group tg1 and p2 is direct child of the root task group. i is the i-th CPU: Global structures  task_group.se: se[i] is the task groups’s sched_entity data for i-th CPU. task_group.cfs_rq: cfs_rq[i] is the task group’s cfs_rq data for i-th CPU. task_group.parent: the parent task group. task_group.shares: the task group cpu.shares task_struct.sched_class: the scheduler class the tasks should be scheduled with.  Per-CPU structures  sched_entity.vruntime: the virtual runtime. sched_entity.parent: the schedule entity of the parent task group. sched_entity.my_q: when not a task (NULL), the task group’s CFS runqueue on the local CPU. sched_entity.run_node: the related red-black tree node on the runqueue tree. sched_entity.cfs_rq: the CFS runqueue that manages the schedule entity sched_entity.load: the weight of the entity. If it relates to a task group, is the sum of the weights of the tasks of the group, on the local CPU. cfs_rq.load: the load of the runqueue, aka the sum of the weights of the entities that compose it. cfs_rq.current: the schedule entity that is currently running on the local CPU, where a group or a task. cfs_rq.rq: the general CPU runqueue to which the CFS runqueue is attached. cfs_rq.tg: the task group that owns the runqueue, whether the root one or a child. rq.cfs_tasks: the linked list containing the reb-black tree nodes (e.g. here CFS puts the next entity into it).   If you would like to explore the relations between the entities, I recommend this blog.\n Now that we introduced runqueues, let’s talk about the further scaling of the runtime weight for task groups schedule entities.\nWeight for task groups As task groups can be run on multiple CPUs doing real multitasking, the weight (i.e. CPU shares) for task group’s runqueue is further updated (scaled) in entity_tick() based on how much the task group is loaded on the local CPU.\nThe weight is multiplied by the ratio of the load of the task group running on the local CPU (which is the task group’s runqueue) to the global load of the task group.\nThis ratio tells us how much the task group is loaded on the local CPU.\n As a detail, this is done if configured Linux for symmetrical multiprocessor, otherwise the shares is not scaled.\n In detail, the load is the sum of the weights of the entities that compose the task group or the task group’s runqueue.\nshares = shares * (runqueue's load / task group's load) TL;DR: the ratio is the sum of the weights of the entities that compose the runqueues to the sum of the weights of the entities that compose the task group:\nThe calculcation is done by the calc_group_shares() function, to get the final value of the task group’s shares that will weight the virtual runtime of the task group schedule entity:\nstatic long calc_group_shares(struct cfs_rq *cfs_rq) { long tg_weight, tg_shares, load, shares; / struct task_group *tg = cfs_rq-tg; /* tg_shares is the task group's CPU shares. */ tg_shares = READ_ONCE(tg-shares); /* load is the load of the local CFS runqueue which is, the load of the task group on the local CPU. */ load = max(scale_load_down(cfs_rq-load.weight), cfs_rq-avg.load_avg); /* tg_weight is the global load of the task group. */ tg_weight = atomic_long_read(\u0026tg-load_avg); /* Ensure tg_weight = load */ tg_weight -= cfs_rq-tg_load_avg_contrib; tg_weight += load; shares = (tg_shares * load); if (tg_weight) shares /= tg_weight; // ... /* shares is now the per CPU-scaled task group shares. */ return clamp_t(long, shares, MIN_SHARES, tg_shares); } This is done to treat fairly also groups among CPUs!\n... shares = (tg_shares * load); if (tg_weight) shares /= tg_weight; ... Consequently, the vruntime is the binary tree key so the entity with the smallest vruntime is picked by __pick_next_entity(), whether is an actual task or a group. If it’s a task group the search is repeated on its runqueue and so on, going through the hierarchy of runqueues until a real task is found to be run.\n As a detail, in order to provide efficiency and to not need to traverse the whole tree every time a scheduling is needed, as the element in an ordered red black tree that is leftmost is the element with a minor key value (i.e. the vruntime) a cache is easily keeped as rb_leftmost variable in each runqueue structure. And it’s ideally picked by pick_next_entity().\n Finally, we can better see the whole picture!\nWrapping up the time accounting Now that we have the most important concepts in mind about time accounting, considering how the weight is calculated for both tasks and tasks groups schedule entities, which are part of hierarchical tasks groups' runqueues, let’s see how the time accounting is honored during the periodic tick, fired by the timer interrupt:\n/* * Called by the timer interrupt handler every 1/HZ seconds. */ scheduler_tick() /* The local CPU */ - int cpu = smp_processor_id(); /* The local CPU runqueue */ - struct rq *rq = cpu_rq(cpu); /* The local CPU runqueue currently running task */ - struct task_struct *curr = rq-curr; /* The current running task's scheduler class' periodic tick function. */ - curr-sched_class-task_tick(rq, curr) /* Let's assume the class is CFS. */ - task_tick_fair() - struct sched_entity *se = \u0026curr-se; /* * For each schedule entity through parent task groups * up to the root task group. */ - for_each_sched_entity(se) /* The runqueue where the entity is placed. */ - cfs_rq = cfs_rq_of(se); - entity_tick(cfs_rq, se) /* * Update the virtual runtime for the current running entity * on the current selected by loop-task group's runqueue. */ - update_curr(cfs_rq) - struct sched_entity *curr = cfs_rq-curr; - delta_exec = now - curr-exec_start; - curr-exec_start = now; - curr-vruntime += calc_delta_fair(delta_exec, curr); /* * If it's a task group update the shares * based on its group runqueue, * which is the group load on the local CPU */ - update_cfs_group(se) /* The CFS runqueue of the entity, if it's a task group. */ - struct cfs_rq *gcfs_rq = group_cfs_rq(se); /* If the entity is a task, skip */ - if (!gcfs_rq) - return; /* * Update the CPU shares for the task group entity. */ - shares = calc_group_shares(gcfs_rq); - reweight_entity(cfs_rq_of(se), se, shares);  The code has been a bit simplified to show a clearer picture.\n So, the next question is: how a runqueue is populated? When a new task is added do a runqueue?\nRunqueues population The runqueues are populated when:\n a clone() is called, and a task wakes up after having slept, via try_to_wake_up() function call  with enqueue_entity().\nAnd the next question is: when a task is removed from the runqueue?\n When a task explicitly exit()s (e.g. via exit() libc function) When a task explicitly or implicitly requests to sleep()  with dequeue_entity().\nIn both enqueue and dequeue cases the rb_leftmost cache is updated and replaced with rb_next() result.\nNow that we have a runqueue populated, how does the scheduler pick one task from there?\nThe scheduler entrypoint schedule() is the main function which (through __schedule), calls pick_next_task that will return the task that ran less.\nFor the sake of simplicity, let’s assume that the hyperthreading support is not configured.\n More on core scheduling here.\n __pick_next_task() picks the highest priority scheduler class which returns the higher priority task, by looping through the hierarchy of task groups' runqueues, until a real task is found. Actually, as we said before, the runqueue red-black trees are not traversed on each schedule, instead, in the end, it picks the rb_leftmost entity rb node, through __pick_next_entity.\nschedule() loops while the currently running task should be rescheduled, which is, is no longer fair to be run.\n The path is a bit different when the core scheduling feature is enabled.\n Then, __schedule() calls context_switch() that switches to the returned task.\nAnd this comes to one of the next topics: context switch. But before talking about that let’s continue talking about the life of a task.\nLet’s imagine that we are in process context and that our task is now running. Not all tasks complete from the time have being scheduled. For example, tasks waiting for events (like for keyboard input or for file I/O) can be put to sleep, and also are in interruptible / uninterruptible state so they aren’t picked from the runqueue.\n 4. Sleep and wake up A task can decide to sleep but something then is needed to wake it up. We should also consider that multiple tasks can wait for some event to occur.\nA wait queue of type wait_queue_head is implemented for this purpose as a doubly-linked list of tasks waiting for some events to occur. It allows tasks to be notified when those events occur by referencing the wait queue, generally from what generates the event itself.\nSleep A task can put itself to sleep in the kernel similar to what does the wait syscall:\n create a wait queue via the DECLARE_WAIT_QUEUE_HEAD() macro add the task itself to it via add_wait_queue() function call set its state to interruptible / uninterruptible via prepare_to_wait(). If the task is set interruptible, signals can wake it up. call schedule() which in turn removes the task from the runqueue via deactivate_task().  /* ‘q’ is the wait queue we wish to sleep on */ DEFINE_WAIT_QUEUE_HEAD(wait); add_wait_queue(q, \u0026wait); while (!condition) { /* condition is the event that we are waiting for */ prepare_to_wait(\u0026q, \u0026wait, TASK_INTERRUPTIBLE); ... schedule(); } It can also do it non voluntarily waiting for semaphores.\n As a detail, wait queues have two implementations, the one we mentioned above and the original one (Linux 2.0) which has been kept for simple use cases and is called now simple wait queues (more on the history here).\n Wake up For the sake of simplicity on the path to waking up let’s take the example of the simple wait queue, as the standard wait queue here is more complex than it is in the preparation to wait, and we don’t need to understand it now.\nTo wake those tasks that are sleeping while waiting for an event here is the flow:\nswake_up_all() (which is pretty analogous to the sibling implementation’s  wake_up_all()) calls try_to_wake_up() and is there to wake all processes in a wait queue when the associated event occurs.\ntry_to_wake_up() does the work that consists of:\n set task state to running - and through ttwu_queue: calls the activate_task() function which adds the task to the runqueue via enqueue_task() sets need_resched flag on the current task if the awakened task has higher priority than the current one (we’ll talk about this flag later) which provokes then a schedule() (and consequent context switch)  swake_up_all() then removes the task from the wait queue.\nSignals Signals, as well, can wake up tasks if they are interruptible. In this case, the task code itself should then manage the spurious wake-up (example), by checking the event that occurs or managing the signal (e.g. inotify does it), and call finish_wait to update its state and remove itself from the wait queue.\nCompleting the sample code above by managing also the waking up part it will end up with something like this:\n/* ‘q’ is the wait queue we wish to sleep on */ DEFINE_WAIT_QUEUE_HEAD(wait); add_wait_queue(q, \u0026wait); while (!condition) { /* condition is the event that we are waiting for */ prepare_to_wait(\u0026q, \u0026wait, TASK_INTERRUPTIBLE); if (signal_pending(current)) /* handle signal */ schedule(); } finish_wait(\u0026q, \u0026wait); As a detail, wake up can be provoked in both process context and interrupt context, during an interrupt handler execution, which is what often device drivers do. Sleep can be only done in process context.\n 5. Context switch and Preemption And this comes to the context switch. For example, when a task starts to sleep a context switch is needed, and the next task is voluntarily picked and the scheduling is done via schedule().\nThe context switch work is done by context_switch(), called by the internal __schedule() and executes:\n switch_mm() (implementation here for x86) to switch virtual memory mappings process-specific. switch_to() (x86_64) to save and restore stack information and all registers which contain process-specific data.  As you saw, both functions are architecture-dependent (ASM) code. The context switch is requested by the tasks themselves voluntarily or by the scheduler, nonvoluntarily from the point of view of a task.\nVoluntary As we saw tasks can trigger context switch via schedule() in kernel space, either when they explicitly request it or when they put themselves to sleep or they try to wake up other ones. Also, context switch happens when tasks block, for example when synchronizing with semaphores or mutexes.\nAnyway, context switches are not done only when code in kernel space voluntarily calls schedule(), otherwise, tasks could monopolize a CPU, so an external component should intervene.\nNonvoluntary: preemption As the main Linux scheduler class is a fair scheduler the fairness must be guaranteed in some way… Ok, but how does it preempt?\nFor this purpose, a flag named need_reschedule is present in the task_struct’s thread_info flags (i.e. x86) and is set or unset on the current task to notify that it should leave the CPU which in turn, after schedule() call, will switch to another process context.\nSo, when this flag is set?\n in scheduler_tick(), which is constantly called by the timer interrupt handler (the architecture-independent part actually), continuously checking and updating vruntime, balancing the runqueues, it sets the flag when preemption is needed. in try_to_wake_up(), when the current task has minor priority than the awakened.  Then, in order to understand when the flag is checked, we can think about when a task preemption is needed and also can be done safely.\nIn userspace Returning from kernelspace to userspace is safe to context switch: if it is safe to switch mode and continue executing the current task, it is also safe to pick a new task to execute. Has this userspace task still to run? Maybe it’s no longer fair to run it. This is what happens when from:\n system calls interrupt handlers  return to userspace.\nIf need_resched is set a schedule is needed, the next entity task is picked, and context switch done.\n As a note, consider that both these paths are architecture-dependent, and typically implemented in assembly in entry.S (e.g. x86_64) which, aside from kernel entry code, also contains kernel exit code).\n In kernel space A note deserves to be explained. The kernel is fully preemptive from 2.6 that is, a task can be preempted as long as the kernel is in a safe state. When preemption can’t be done, locks are in place to mark it, so that a safe state is defined when the kernel doesn’t hold a lock. Basically, a lock counter preempt_count is added to thread_info flags (x86) to let preempt tasks that are running in kernelspace only when it’s equal to zero.\nUpon return from interrupt to kernelspace or from process context during preemption, if need_resched is set and preempt_count == 0 the current task is preempted, otherwise the interrupt returns to the interrupted task.\nAlso, every time preempt_count is updated and decreased to zero and need_resched is true, preemption is done.\nFor example, considering the return path from interrupt which is architecture-dependent, the xtensa ISA’s common exception exit path is pretty self-explanatory:\ncommon_exception_return: ... #ifdef CONFIG_PREEMPTION 6: _bbci.la4, TIF_NEED_RESCHED, 4f /* Check current_thread_info-preempt_count */ l32ia4, a2, TI_PRE_COUNT bneza4, 4f abi_callpreempt_schedule_irq j4f #endif ...  TL;DR About what we said above, you can check the __schedule() function comments.\n Moreover, the kernel is SMP-safe that is, a task can be safely restored in a symmetrical multi-processor.\nYou can check both preemption config and SMP config (x86) in your running kernel version from procfs:\n$ zcat /proc/config.gz | grep \"CONFIG_SMP\\|CONFIG_PREEMPT\" | grep -v \"^#\" CONFIG_PREEMPT_BUILD=y CONFIG_PREEMPT=y CONFIG_PREEMPT_COUNT=y CONFIG_PREEMPTION=y CONFIG_PREEMPT_DYNAMIC=y CONFIG_PREEMPT_RCU=y CONFIG_SMP=y CONFIG_PREEMPT_NOTIFIERS=y That’s all folks! We’ve arrived to the end of this little journey.\n Conclusion  The linked code refers to Linux 5.17.9.\n I liked the idea to leave you the choice to dig into each single path the kernel does to manage the tasks scheduling. That’s why I intentionally didn’t include so many snippets, instead providing you the code face of the coin for almost every path we saw, through links to the real Linux code.\nWhat is incredible is that, even if it’s one of the largest OSS projects, you can understand how Linux works and also contribute. That’s why I love open source more every day!\nThank you! I hope this was interesting for you as it was for me. Please, feel free to reach out!\n twitter github linkedin  Links  https://www.kernel.org/doc/html/v5.17/scheduler/index.html https://elixir.bootlin.com/linux/v5.17.9/source https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468 https://mechpen.github.io/posts/2020-04-27-cfs-group/index.html#2.2.-data-structures https://josefbacik.github.io/kernel/scheduler/2017/07/14/scheduler-basics.html https://opensource.com/article/19/2/fair-scheduling-linux https://lwn.net/Articles/531853/ https://oska874.gitbooks.io/process-scheduling-in-linux/content/  ","wordCount":"4458","inLanguage":"en","datePublished":"2022-06-24T00:00:00+02:00","dateModified":"2022-06-24T00:00:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://maxgio92.github.io/posts/linux-scheduler-journey/"},"publisher":{"@type":"Organization","name":"Maxgio's blog","logo":{"@type":"ImageObject","url":"http://maxgio92.github.io/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=http://maxgio92.github.io/ accesskey=h title="Maxgio's blog (Alt + H)">Maxgio's blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://maxgio92.github.io/posts title=Posts><span>Posts</span></a></li><li><a href=http://maxgio92.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=http://maxgio92.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/maxgio92 title=Github><span>Github</span></a></li><li><a href=https://hachyderm.io/@maxgio92 title=Mastodon><span>Mastodon</span></a></li><li><a href=https://twitter.com/maxgio92 title=Twitter><span>Twitter</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://maxgio92.github.io/>Home</a>&nbsp;»&nbsp;<a href=http://maxgio92.github.io/posts/>Posts</a></div><h1 class=post-title>A journey into the Linux scheduler</h1><div class=post-meta><span title="2022-06-24 00:00:00 +0200 +0200">June 24, 2022</span>&nbsp;·&nbsp;21 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><ul><li><a href=#1-resource-sharing-is-the-key aria-label="1. Resource sharing is the key!">1. Resource sharing is the key!</a></li><li><a href=#2-time-accounting aria-label="2. Time accounting">2. Time accounting</a><ul><li><a href=#the-runtime aria-label="The runtime">The runtime</a></li><li><a href=#the-virtual-runtime aria-label="The virtual runtime">The virtual runtime</a><ul><li><a href=#example aria-label=Example>Example</a></li><li><a href=#implementation aria-label=Implementation>Implementation</a></li></ul></li><li><a href=#the-schedule-entities aria-label="The schedule entities">The schedule entities</a></li><li><a href=#the-weight aria-label="The weight">The weight</a></li><li><a href=#update-of-the-virtual-runtime aria-label="Update of the virtual runtime">Update of the virtual runtime</a></li></ul></li><li><a href=#3-task-selection aria-label="3. Task selection">3. Task selection</a><ul><li><a href=#the-runqueues aria-label="The runqueues">The runqueues</a><ul><li><a href=#in-a-nutshell aria-label="In a nutshell">In a nutshell</a></li></ul></li><li><a href=#wrapping-up-the-structures aria-label="Wrapping up the structures">Wrapping up the structures</a><ul><li><a href=#global-structures aria-label="Global structures">Global structures</a></li><li><a href=#per-cpu-structures aria-label="Per-CPU structures">Per-CPU structures</a></li></ul></li><li><a href=#weight-for-task-groups aria-label="Weight for task groups">Weight for task groups</a></li><li><a href=#wrapping-up-the-time-accounting aria-label="Wrapping up the time accounting">Wrapping up the time accounting</a></li><li><a href=#runqueues-population aria-label="Runqueues population">Runqueues population</a></li><li><a href=#the-scheduler-entrypoint aria-label="The scheduler entrypoint">The scheduler entrypoint</a></li></ul></li><li><a href=#4-sleep-and-wake-up aria-label="4. Sleep and wake up">4. Sleep and wake up</a><ul><li><a href=#sleep aria-label=Sleep>Sleep</a></li><li><a href=#wake-up aria-label="Wake up">Wake up</a><ul><li><a href=#signals aria-label=Signals>Signals</a></li></ul></li></ul></li><li><a href=#5-context-switch-and-preemption aria-label="5. Context switch and Preemption">5. Context switch and Preemption</a><ul><li><a href=#voluntary aria-label=Voluntary>Voluntary</a></li><li><a href=#nonvoluntary-preemption aria-label="Nonvoluntary: preemption">Nonvoluntary: preemption</a><ul><ul><li><a href=#in-userspace aria-label="In userspace">In userspace</a></li><li><a href=#in-kernel-space aria-label="In kernel space">In kernel space</a></li></ul></ul></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul><li><a href=#thank-you aria-label="Thank you!">Thank you!</a></li><li><a href=#links aria-label=Links>Links</a></li></ul></div></details></div><div class=post-content><p>Two years ago more or less I started my journey in Linux. I was scared at first and I didn&rsquo;t know where to start from.
But then I decided to buy a <a href=https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468>book</a> - and what a book! - in order to follow a path.</p><p>Along the way, I integrated the material with up-to-date documentation from <a href=https://docs.kernel.org>kernel.org</a> and <a href=https://elixir.bootlin.com/linux/v5.17.9/source>source code</a>. In the meantime, I started to learn C a bit so that I also could have <a href=https://github.com/maxgio92/linux/tree/syscall/maxgio>played</a> with what I was learning, step by step.</p><p>One of the things I was fascinated by was how Linux is able to manage and let the CPU run thousands and thousands of processes each second.
To give you an idea, right now, Linux on my laptop configured with an Intel i7-1185G7 CPU switched context 28,428 times in a second! That’s fantastic, isn’t it?</p><div class=highlight><pre class=chroma><code class=language-shell data-lang=shell>$ perf stat -e sched:sched_switch --timeout <span class=m>1000</span>
 Performance counter stats <span class=k>for</span> <span class=s1>&#39;system wide&#39;</span>:
            28,428      sched:sched_switch
       1.001137885 seconds <span class=nb>time</span> elapsed
</code></pre></div><p>During this journey inside Linux, I&rsquo;ve written notes as it helps me to digest and re-process in my own way the informations I learn. Then I thought: &ldquo;Maybe they&rsquo;re useful to someone. Why not share them?”.</p><p>So here I am with with a blog.</p><hr><h2 id=1-resource-sharing-is-the-key>1. Resource sharing is the key!<a hidden class=anchor aria-hidden=true href=#1-resource-sharing-is-the-key>#</a></h2><p>Let’s dive into the Linux component which is responsible for doing such great work: the scheduler.</p><p>In order to do it, imagine what we would expect from an operating system. Let&rsquo;s say that we’d want it to run tasks that we need to complete, providing the OS hardware resources.
Tasks come of different natures but we can simply categorize them as CPU-intensive and interactive ones.</p><p>Something should provide the efficiency of task completion and responsiveness. Consider a typewriter that prints letters with 1s second of delay, it would be impossible to use!
So, in a few words, I would like to request to the scheduler: “I want to execute this task and I want it’s completed when I need or to respond when I need”.
The goal of a scheduler is to decide “what runs next” leading to have the best balance between the needings of the different natures of the tasks.</p><p>As Linux is a <em>preemptive multitasking</em> operating system, the completely fair scheduler (CFS) came to Linux, as the replacement of the O(1) scheduler from the 2.6.23, with the aim to guarantee the fairness of CPU owning by the tasks, and at the same time tailoring to a broad nature range of tasks. Although the algorithm complexity didn&rsquo;t see an improvement, from O(1) to O(log N), the reduced latency removed issues when dealing with interactive tasks.</p><p>As a side note consider that the Linux scheduler is made of different <a href=https://www.kernel.org/doc/html/v5.17/scheduler/sched-design-CFS.html#scheduling-classes>scheduler classes</a> (<a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L2117>code</a>), of which the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L11737>CFS class</a> is the highest-priority one. Another one is the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/rt.c#L2642>real-time</a> scheduler class, tailored as the name suggests for tasks that need responsiveness.</p><p>Interactive tasks would run for small amounts of time but need to run quickly as events happen. CPU-intensive tasks don’t require to complete ASAP but require longer CPU time.
Based on that, time accounting is what guarantees fairness in the Linux CFS scheduler as long as the task that runs for less time will run next.</p><p>This comes to the time accounting, so let&rsquo;s start to dig into it!</p><hr><h2 id=2-time-accounting>2. Time accounting<a hidden class=anchor aria-hidden=true href=#2-time-accounting>#</a></h2><p>Linux CFS actually does not directly assign timeslices to tasks as the O(1) scheduler did, instead it measures execution time, in order to be flexible with respect to both interactive and processor-intensive tasks.</p><h3 id=the-runtime>The runtime<a hidden class=anchor aria-hidden=true href=#the-runtime>#</a></h3><p>Remember, the fundamental rule in the Completely Fair Scheduler is: <em>the task that ran less, will run next</em>! Which is, each task should have its fair slice of processor time <em>when it needs</em>!
For example, interactive tasks can run frequently but for less time than intensive ones, and still have their fair amount of CPU time.</p><p>The implementation is written in the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L844><code>update_curr()</code></a> function, which is called periodically to account tasks for the CPU time they used in the last period (<a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L853><code>delta_exec</code></a>).</p><h3 id=the-virtual-runtime>The virtual runtime<a hidden class=anchor aria-hidden=true href=#the-virtual-runtime>#</a></h3><p>The execution time is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L870>further weighted</a> to implement priority between tasks. This is done by the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L233>fair delta calculation</a>. The more the weight, the more time the task will have.</p><h4 id=example>Example<a hidden class=anchor aria-hidden=true href=#example>#</a></h4><p>Let' do an example with timeslices: considering a single CPU, if every T time period two tasks A and B run respectively with a weight of 1 and 2, the allocated CPU time is obtained by multiplying T by the ratio of the weight to the sum of the weights of all running tasks:</p><pre><code>CPU_timeslice(A) = T * (1 / (1 + 2))).
CPU_timeslice(B) = T * (2 / (1 + 2))).
</code></pre><p>For each T time period, task A will run for 0.334~T and task B 0.667~T.</p><blockquote><p>This is what is calculated <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L710>here</a>.</p></blockquote><h4 id=implementation>Implementation<a hidden class=anchor aria-hidden=true href=#implementation>#</a></h4><p>Coming to the actual implementation, the CFS class accounts tasks for their real execution time considering their weight, which is ensured by periodically measuring the <code>runtime</code> and multiplying it by the ratio <code>weight/(base weight)</code>.</p><pre><code>runtime += runtime * (w / base w)).
</code></pre><p>Which is exactly what is done in <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L844><code>update_curr()</code></a>:</p><pre><code>static void update_curr(struct cfs_rq *cfs_rq)
{
	struct sched_entity *curr = cfs_rq-&gt;curr;
	...
	delta_exec = now - curr-&gt;exec_start;
	...
	curr-&gt;vruntime += calc_delta_fair(delta_exec, curr);
	...
}
</code></pre><p>And the result is the so-called virtual runtime (<a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L547><code>vruntime</code></a>).</p><p>As the weight implementation <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L873>depends</a> on the nature of the schedule entities, let&rsquo;s spend a couple of words about them.</p><blockquote><p>Indeed, the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L547><code>vruntime</code></a> is a member of the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L538><code>sched_entity</code></a> structure.</p></blockquote><p>Then, we&rsquo;ll talk more about the runtime weight.</p><h3 id=the-schedule-entities>The schedule entities<a hidden class=anchor aria-hidden=true href=#the-schedule-entities>#</a></h3><p>Until now we talked about tasks as the only schedulable entity but actually, tasks can be put into group of tasks, in order to treat a group equally to a single task, and have the group share the resources (I.e. CPU) between the entities of the group without afflicting the overall system.
That’s the case of <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L877>cgroups</a> and why they’re there.</p><p>Also, task groups can be composed of other groups, and there is a root group.
In the end, a running Linux is likely going to manage a hierarchy tree of schedule entities.
So when a task should be <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L11153>accounted for time</a>, also the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L11158>parent group&rsquo;s entity</a> should be, and so on, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L282>until the root group entity</a> is found.</p><blockquote><p>Consider that the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L538><code>sched_entity</code></a> structure is the structure that tracks information about the scheduling, like the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L547><code>vruntime</code></a>, and it refers to tasks or tasks group structures. As they track scheduling data, they are per-CPU structures. Instead, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L728><code>task_struct</code></a> and <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L391><code>task_group</code></a> structures, are global.</p></blockquote><p>And this comes to the weight.</p><h3 id=the-weight>The weight<a hidden class=anchor aria-hidden=true href=#the-weight>#</a></h3><p>We said before that the weight implementation depends on the nature of the entity. If the entity is a task the weight is represented by the <a href=https://www.kernel.org/doc/html/latest/scheduler/sched-nice-design.html>niceness</a> value (<a href=https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L1861>code</a>).
If it’s a task group, the weight is represented by the CPU <a href=https://elixir.bootlin.com/linux/latest/source/kernel/sched/sched.h#L384>shares</a> value.</p><blockquote><p>In cgroup v2 the <code>shares</code> is named directly <code>weight</code>.</p></blockquote><p>In the end, the weight is what matters: in the case of tasks the niceness is converted <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched/prio.h#L26>to priority</a> and then <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L10902>to weight</a> (<a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L10750>here</a>). In the case of task groups the user-visible value is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L10718>internally converted</a>.</p><p>For the sake of simplicity let’s remember this: the groups are hierarchical, and a task is part of a task group. The bigger the depth of the hierarchy, the more the weight gets diluted. Adding a heavily weighted task to one child group is not going to afflict the overall tasks tree the same as it would do if it was part of the root group. This is because the task weight is relative to the group which the task is put into.</p><p>Each entity, whether a task or a task group, is treated the same. The time accounting is applied <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4586>to the currently locally running entity</a> and <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L11158>recursively up through the hierarchy</a>.</p><blockquote><p>In case of task groups, the weight is further scaled, but don&rsquo;t worry, we&rsquo;ll talk about it later.</p></blockquote><h3 id=update-of-the-virtual-runtime>Update of the virtual runtime<a hidden class=anchor aria-hidden=true href=#update-of-the-virtual-runtime>#</a></h3><p>This virtual runtime is updated on the schedule entity that is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L846>currently running</a> on the local CPU via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L844><code>update_curr()</code></a> function, which is called:</p><ul><li>whenever a task <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4272>becomes runnable</a>, or</li><li>whenever <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4371>blocks</a> become <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L111>unrunnable</a>, and</li><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L5250>periodically</a> (every 1/<a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/Kconfig.hz#L51><code>CONFIG_HZ</code></a> seconds) by the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/time/tick-common.c#L85>system timer interrupt handler</a>.</li></ul><blockquote><p>As a detail, the virtual runtime value if the task is just forked, is initialized to a <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L529>minimum value</a> which depends on the runqueue load (<a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L540><code>cfs_rq->min_vruntime</code></a>).</p></blockquote><p>And this leads to the next question: how this accounting is honored in the task selection in the scheduler in order to guarantee fairness of execution?</p><hr><h2 id=3-task-selection>3. Task selection<a hidden class=anchor aria-hidden=true href=#3-task-selection>#</a></h2><p>The schedule entities eligible to run (which is in a <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L83>runnable state</a>) are put in a run queue, which is implemented as a <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L532>red black self-balancing binary tree</a> that contains schedule entity structures ordered by <code>vruntime</code>.</p><h3 id=the-runqueues>The runqueues<a hidden class=anchor aria-hidden=true href=#the-runqueues>#</a></h3><p>Runqueues are per-CPU structures and contain schedule entities and they have a <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L556>pointer</a> to the entity which is currently running on the related CPU. The schedule entities they refer to are related to the local CPU because the <code>sched_entity</code>s contain information about scheduling and thus are specific to a CPU. The <code>vruntime</code> is the binary tree key so the entity with the smallest <code>vruntime</code> is picked during a new schedule.</p><blockquote><p>Each scheduler class has its specific runqueue, which <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L962>are part</a> of the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L926>general runqueues</a>. Anyway, let&rsquo;s consider now only CFS runqueues.</p></blockquote><p>In turn, also each task group has a dedicated <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L398>CFS runqueue</a>, from the root task group through its child task groups. <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L606><code>__pick_next_entity()</code></a> picks the entity with the smallest virtual runtime, whether is an actual task or a group. If it’s a task group the search is repeated on its runqueue and so on, going through the hierarchy of runqueues <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L7206>until a real task is found to be run</a>.</p><p>Each runqueue keeps track of the schedule entities that are running/runnable on the local CPU.</p><h4 id=in-a-nutshell>In a nutshell<a hidden class=anchor aria-hidden=true href=#in-a-nutshell>#</a></h4><ul><li>Tasks groups are global.</li><li>Tasks also are global.</li><li>Every task is part of a task group.</li><li>There is one runqueue per task group per CPU.</li><li>Runqueues are composed of schedule entities.</li><li>Schedule entities reference tasks or task groups.</li><li>Schedule entities are per CPU</li></ul><h3 id=wrapping-up-the-structures>Wrapping up the structures<a hidden class=anchor aria-hidden=true href=#wrapping-up-the-structures>#</a></h3><p>To make it more clear, let&rsquo;s see a practical example.
You can see below a diagram for a sample scenario where there are two tasks (<code>p1</code> and <code>p2</code>), and two task groups (root task group and <code>tg1</code>, child of the root task group). And <code>p1</code> is direct child of task group <code>tg1</code> and <code>p2</code> is direct child of the root task group. <code>i</code> is the <em>i</em>-th CPU:
<img loading=lazy src=/images/linux_sched_structs.png alt="Linux Scheduler entities relations"></p><h4 id=global-structures>Global structures<a hidden class=anchor aria-hidden=true href=#global-structures>#</a></h4><ul><li><code>task_group.se</code>: <code>se[i]</code> is the task groups&rsquo;s <code>sched_entity</code> data for <em>i</em>-th CPU.</li><li><code>task_group.cfs_rq</code>: <code>cfs_rq[i]</code> is the task group&rsquo;s <code>cfs_rq</code> data for <em>i</em>-th CPU.</li><li><code>task_group.parent</code>: the parent task group.</li><li><code>task_group.shares</code>: the task group <code>cpu.shares</code></li><li><code>task_struct.sched_class</code>: the scheduler class the tasks should be scheduled with.</li></ul><h4 id=per-cpu-structures>Per-CPU structures<a hidden class=anchor aria-hidden=true href=#per-cpu-structures>#</a></h4><ul><li><code>sched_entity.vruntime</code>: the virtual runtime.</li><li><code>sched_entity.parent</code>: the schedule entity of the parent task group.</li><li><code>sched_entity.my_q</code>: when not a task (<code>NULL</code>), the task group&rsquo;s CFS runqueue on the local CPU.</li><li><code>sched_entity.run_node</code>: the related red-black tree node on the runqueue tree.</li><li><code>sched_entity.cfs_rq</code>: the CFS runqueue that manages the schedule entity</li><li><code>sched_entity.load</code>: the weight of the entity. If it relates to a task group, is the sum of the weights of the tasks of the group, on the local CPU.</li><li><code>cfs_rq.load</code>: the load of the runqueue, aka the sum of the weights of the entities that compose it.</li><li><code>cfs_rq.current</code>: the schedule entity that is currently running on the local CPU, where a group or a task.</li><li><code>cfs_rq.rq</code>: the general CPU runqueue to which the CFS runqueue is attached.</li><li><code>cfs_rq.tg</code>: the task group that owns the runqueue, whether the root one or a child.</li><li><code>rq.cfs_tasks</code>: the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/types.h#L178>linked list</a> containing the reb-black tree nodes (e.g. <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L7320>here</a> CFS puts the next entity into it).</li></ul><blockquote><p>If you would like to explore the relations between the entities, I recommend <a href=https://mechpen.github.io/posts/2020-04-27-cfs-group/index.html#2.2.-data-structures>this blog</a>.</p></blockquote><p>Now that we introduced runqueues, let&rsquo;s talk about the further scaling of the runtime weight for task groups schedule entities.</p><h3 id=weight-for-task-groups>Weight for task groups<a hidden class=anchor aria-hidden=true href=#weight-for-task-groups>#</a></h3><p>As <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L391>task groups</a> can be run on multiple CPUs doing real multitasking, the weight (i.e. CPU shares) for task group&rsquo;s runqueue is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4592>further updated</a> (scaled) in <code>entity_tick()</code> based on how much the task group is loaded on the local CPU.</p><p>The weight is multiplied by the ratio of the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/sched.h#L533>load</a> of the task group running on the local CPU (which is the task group&rsquo;s runqueue) to the global load of the task group.</p><p>This ratio tells us how much the task group is loaded on the local CPU.</p><blockquote><p>As a detail, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L3215>this is done</a> if configured Linux for symmetrical multiprocessor, otherwise the <code>shares</code> <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L3209>is not scaled</a>.</p></blockquote><p>In detail, the load is the sum of the weights of the entities that compose the task group or the task group&rsquo;s runqueue.</p><pre><code>shares = shares * (runqueue's load / task group's load)
</code></pre><p>TL;DR: the ratio is the sum of the weights of the entities that compose the runqueues to the sum of the weights of the entities that compose the task group:</p><p>The calculcation is done by the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L3157><code>calc_group_shares()</code></a> function, to get the final value of the task group&rsquo;s shares that will weight the virtual runtime of the task group schedule entity:</p><pre><code>static long calc_group_shares(struct cfs_rq *cfs_rq)
{
	long tg_weight, tg_shares, load, shares;
	/
	struct task_group *tg = cfs_rq-&gt;tg;

	/*
	   tg_shares is the task group's CPU shares.
	 */
	tg_shares = READ_ONCE(tg-&gt;shares);

	/*
	   load is the load of the local CFS runqueue which is,
	   the load of the task group on the local CPU.
	 */
	load = max(scale_load_down(cfs_rq-&gt;load.weight), cfs_rq-&gt;avg.load_avg);

	/*
	   tg_weight is the global load of the task group.
	 */
	tg_weight = atomic_long_read(&amp;tg-&gt;load_avg);

	/* Ensure tg_weight &gt;= load */
	tg_weight -= cfs_rq-&gt;tg_load_avg_contrib;
	tg_weight += load;

	shares = (tg_shares * load);
	if (tg_weight)
		shares /= tg_weight;

	// ...

	/*
	   shares is now the per CPU-scaled task group shares.
	*/
	return clamp_t(long, shares, MIN_SHARES, tg_shares);
}
</code></pre><p>This is done to treat fairly also groups among CPUs!</p><pre><code>...
shares = (tg_shares * load);
	if (tg_weight)
		shares /= tg_weight;
...
</code></pre><p>Consequently, the <code>vruntime</code> is the binary tree key so the entity with the smallest <code>vruntime</code> is picked by <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L606><code>__pick_next_entity()</code></a>, whether is an actual task or a group. If it’s a task group the search is repeated on its runqueue and so on, going through the hierarchy of runqueues until a real task is found to be run.</p><blockquote><p>As a detail, in order to provide efficiency and to not need to <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L606>traverse</a> the whole tree every time a scheduling is needed, as the element in an ordered red black tree that is leftmost is the element with a minor key value (i.e. the <code>vruntime</code>) a cache <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L588>is easily keeped</a> as <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/rbtree_types.h#L28><code>rb_leftmost</code></a> variable in each runqueue structure. And it&rsquo;s <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4518>ideally picked</a> by <code>pick_next_entity()</code>.</p></blockquote><p>Finally, we can better see the whole picture!</p><h3 id=wrapping-up-the-time-accounting>Wrapping up the time accounting<a hidden class=anchor aria-hidden=true href=#wrapping-up-the-time-accounting>#</a></h3><p>Now that we have the most important concepts in mind about time accounting, considering how the weight is calculated for both tasks and tasks groups schedule entities, which are part of hierarchical tasks groups' runqueues, let&rsquo;s see how the time accounting is honored during the periodic tick, fired by the timer interrupt:</p><pre><code>/*
 * Called by the timer interrupt handler every 1/HZ seconds.
 */
scheduler_tick()
/* The local CPU */
-&gt; int cpu = smp_processor_id();
/* The local CPU runqueue */
-&gt; struct rq *rq = cpu_rq(cpu);
/* The local CPU runqueue currently running task */
-&gt; struct task_struct *curr = rq-&gt;curr;
/* The current running task's scheduler class' periodic tick function. */
-&gt; curr-&gt;sched_class-&gt;task_tick(rq, curr)
   /* Let's assume the class is CFS. */
   -&gt; task_tick_fair()
      -&gt; struct sched_entity *se = &amp;curr-&gt;se;
      /*
       * For each schedule entity through parent task groups
       * up to the root task group.
       */
      -&gt; for_each_sched_entity(se)
         /* The runqueue where the entity is placed. */
         -&gt; cfs_rq = cfs_rq_of(se);
         -&gt; entity_tick(cfs_rq, se)
            /*
             * Update the virtual runtime for the current running entity
             * on the current selected by loop-task group's runqueue.
             */
            -&gt; update_curr(cfs_rq)
               -&gt; struct sched_entity *curr = cfs_rq-&gt;curr;
               -&gt; delta_exec = now - curr-&gt;exec_start;
               -&gt; curr-&gt;exec_start = now;
               -&gt; curr-&gt;vruntime += calc_delta_fair(delta_exec, curr);
            /*
             * If it's a task group update the shares 
             * based on its group runqueue,
             * which is the group load on the local CPU
             */
            -&gt; update_cfs_group(se)
               /* The CFS runqueue of the entity, if it's a task group. */
               -&gt; struct cfs_rq *gcfs_rq = group_cfs_rq(se);
               /* If the entity is a task, skip */
               -&gt; if (!gcfs_rq)
               -&gt;   return;
               /*
                * Update the CPU shares for the task group entity.
                */
               -&gt; shares = calc_group_shares(gcfs_rq);
               -&gt; reweight_entity(cfs_rq_of(se), se, shares);
</code></pre><blockquote><p>The code has been a bit simplified to show a clearer picture.</p></blockquote><p>So, the next question is: how a runqueue is populated? When a new task is added do a runqueue?</p><h3 id=runqueues-population>Runqueues population<a hidden class=anchor aria-hidden=true href=#runqueues-population>#</a></h3><p>The runqueues are populated when:</p><ul><li>a <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/fork.c#L2524><code>clone()</code></a> is called, and</li><li>a task wakes up after having slept, via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3985><code>try_to_wake_up()</code></a> function call</li></ul><p>with <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4260><code>enqueue_entity()</code></a>.</p><p>And the next question is: when a task is removed from the runqueue?</p><ul><li>When a task explicitly <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/exit.c#L733><code>exit()</code></a>s (e.g. via <a href=https://man7.org/linux/man-pages/man3/exit.3.html><code>exit()</code></a> libc function)</li><li>When a task explicitly or implicitly requests to <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/wait.c#L261><code>sleep()</code></a></li></ul><p>with <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4366><code>dequeue_entity()</code></a>.</p><p>In both enqueue and dequeue cases the <code>rb_leftmost</code> cache is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/rbtree.h#L165><code>updated</code></a> and replaced with <a href=https://elixir.bootlin.com/linux/v5.17.9/source/lib/rbtree.c#L492><code>rb_next()</code></a> result.</p><p>Now that we have a runqueue populated, how does the scheduler pick one task from there?</p><h3 id=the-scheduler-entrypoint>The scheduler entrypoint<a hidden class=anchor aria-hidden=true href=#the-scheduler-entrypoint>#</a></h3><p><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6377><code>schedule()</code></a> is the main function which (through <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6189><code>__schedule</code></a>), calls <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L5681><code>pick_next_task</code></a> that will return the task that ran less.</p><p>For the sake of simplicity, let&rsquo;s assume that the <a href=https://lwn.net/Articles/861251/>hyperthreading support</a> is not <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/Kconfig.preempt#L117>configured</a>.</p><blockquote><p>More on core scheduling <a href=https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/core-scheduling.html>here</a>.</p></blockquote><p><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L5604><code>__pick_next_task()</code></a> picks the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L5615>highest priority scheduler class</a> which returns the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L7213>higher priority task</a>, by looping through the hierarchy of task groups' runqueues, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L7269>until</a> a real task is found. Actually, as we said before, the runqueue red-black trees are not traversed on each schedule, instead, in the end, it picks the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/rbtree.h#L106><code>rb_leftmost</code></a> entity rb node, through <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4528><code>__pick_next_entity</code></a>.</p><p><code>schedule()</code> loops <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6386>while</a> the currently running task should be rescheduled, which is, is no longer fair to be run.</p><blockquote><p>The path is a bit <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L5695>different</a> when the <a href=https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/core-scheduling.html>core scheduling</a> feature is enabled.</p></blockquote><p>Then, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6189><code>__schedule()</code></a> calls <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L4945><code>context_switch()</code></a> that switches to the returned task.</p><p>And this comes to one of the next topics: context switch. But before talking about that let’s continue talking about the life of a task.</p><p>Let’s imagine that we are in process context and that our task is now running.
Not all tasks complete from the time have being scheduled.
For example, tasks waiting for events (like for keyboard input or for file I/O) can be put to sleep, and also are in <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L84>interruptible</a> / <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L85>uninterruptible</a> state so they aren’t picked from the runqueue.</p><hr><h2 id=4-sleep-and-wake-up>4. Sleep and wake up<a hidden class=anchor aria-hidden=true href=#4-sleep-and-wake-up>#</a></h2><p>A task can decide to sleep but something then is needed to wake it up. We should also consider that multiple tasks can wait for some event to occur.</p><p>A wait queue of type <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/wait.h#L37><code>wait_queue_head</code></a> is implemented for this purpose as a doubly-linked list of tasks waiting for some events to occur.
It allows tasks to be notified when those events occur by referencing the wait queue, generally from what generates the event itself.</p><h3 id=sleep>Sleep<a hidden class=anchor aria-hidden=true href=#sleep>#</a></h3><p>A task can put itself to sleep in the kernel similar to what does the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/wait.c#L18><code>wait</code></a> syscall:</p><ul><li>create a wait queue via the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/wait.h#L61><code>DECLARE_WAIT_QUEUE_HEAD()</code></a> macro</li><li>add the task itself to it via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/wait.c#L18><code>add_wait_queue()</code></a> function call</li><li>set its state to <a href=https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L84>interruptible</a> / <a href=https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L85>uninterruptible</a> via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/wait.c#L261><code>prepare_to_wait()</code></a>. If the task is set interruptible, signals can wake it up.</li><li>call <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6377><code>schedule()</code></a> which in turn removes the task from the runqueue via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L2041><code>deactivate_task()</code></a>.</li></ul><pre><code>/* ‘q’ is the wait queue we wish to sleep on */
DEFINE_WAIT_QUEUE_HEAD(wait); 
add_wait_queue(q, &amp;wait);

while (!condition) { /* condition is the event that we are waiting for */ 
	prepare_to_wait(&amp;q, &amp;wait, TASK_INTERRUPTIBLE);
	...
	schedule(); 
}
</code></pre><p>It can also do it non voluntarily waiting for <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/semaphore.h#L15>semaphores</a>.</p><blockquote><p>As a detail, wait queues have two implementations, the one we mentioned above and the original one (Linux 2.0) which has been kept for simple use cases and is called now <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/swait.h#L48>simple wait queues</a> (more on the history <a href=https://lwn.net/Articles/577370/>here</a>).</p></blockquote><h3 id=wake-up>Wake up<a hidden class=anchor aria-hidden=true href=#wake-up>#</a></h3><p>For the sake of simplicity on the path to waking up let’s take the example of the simple wait queue, as the standard wait queue here is more complex than it is in the preparation to wait, and we don&rsquo;t need to understand it now.</p><p>To wake those tasks that are sleeping while waiting for an event here is the flow:</p><p><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/swait.c#L62><code>swake_up_all()</code></a> (which is pretty analogous to the sibling implementation&rsquo;s <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/wait.h#L224><code>wake_up_all()</code></a>) calls <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3985><code>try_to_wake_up()</code></a> and is there to wake all processes in a wait queue when the associated event occurs.</p><p><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3985><code>try_to_wake_up()</code></a> does the work that consists of:</p><ul><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L4083>set task state</a> to <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L83>running</a> - and through <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3801><code>ttwu_queue</code></a>:</li><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3615>calls</a> the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L2034><code>activate_task()</code></a> function which adds the task to the runqueue via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L2000><code>enqueue_task()</code></a></li><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L2125>sets <code>need_resched</code></a> flag on the current task if the awakened task has higher priority than the current one (we’ll talk about this flag later) which provokes then a <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L996><code>schedule()</code></a> (and consequent context switch)</li></ul><p><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/swait.c#L62><code>swake_up_all()</code></a> then <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/swait.c#L73>removes</a> the task from the wait queue.</p><h4 id=signals>Signals<a hidden class=anchor aria-hidden=true href=#signals>#</a></h4><p>Signals, as well, can wake up tasks if they are <a href=https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h#L84>interruptible</a>.
In this case, the task code itself should then manage the spurious wake-up (<a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/wait.c#L435>example</a>), by checking the event that occurs or <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched/signal.h#L363>managing the signal</a> (e.g. <a href=https://elixir.bootlin.com/linux/v5.17.9/source/fs/notify/inotify/inotify_user.c#L235><code>inotify</code></a> does it), and call <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/wait.c#L388><code>finish_wait</code></a> to update its state and remove itself from the wait queue.</p><p>Completing the sample code above by managing also the waking up part it will end up with something like this:</p><pre><code>/* ‘q’ is the wait queue we wish to sleep on */
DEFINE_WAIT_QUEUE_HEAD(wait); 
add_wait_queue(q, &amp;wait);

while (!condition) { /* condition is the event that we are waiting for */ 
	prepare_to_wait(&amp;q, &amp;wait, TASK_INTERRUPTIBLE);
	if (signal_pending(current))
 		/* handle signal */
	schedule(); 
}
finish_wait(&amp;q, &amp;wait); 
</code></pre><p>As a detail, wake up can be provoked in both process context and interrupt context, during an interrupt handler execution, which is what often device drivers do. Sleep can be only done in process context.</p><hr><h2 id=5-context-switch-and-preemption>5. Context switch and Preemption<a hidden class=anchor aria-hidden=true href=#5-context-switch-and-preemption>#</a></h2><p>And this comes to the context switch.
For example, when a task starts to sleep a context switch is needed, and the next task is voluntarily picked and the scheduling is done via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6377><code>schedule()</code></a>.</p><p>The context switch work is done by <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L4945><code>context_switch()</code></a>, called by the internal <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6189><code>__schedule()</code></a> and executes:</p><ul><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/include/asm/mmu_context.h#L128><code>switch_mm()</code></a> (implementation <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/mm/tlb.c#L488>here</a> for x86) to switch virtual memory mappings process-specific.</li><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/entry/entry_64.S#L225><code>switch_to()</code> (x86_64)</a> to save and restore stack information and all registers which contain process-specific data.</li></ul><p>As you saw, both functions are architecture-dependent (ASM) code.
The context switch is requested by the tasks themselves voluntarily or by the scheduler, nonvoluntarily from the point of view of a task.</p><h3 id=voluntary>Voluntary<a hidden class=anchor aria-hidden=true href=#voluntary>#</a></h3><p>As we saw tasks can trigger context switch via <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6377><code>schedule()</code></a> in kernel space, either when they explicitly request it or when they put themselves to sleep or they try to wake up other ones. Also, context switch happens when tasks block, for example when synchronizing with <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/semaphore.h#L15>semaphores</a> or <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/mutex.h#L63>mutexes</a>.</p><p>Anyway, context switches are not done only when code in kernel space voluntarily calls <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6377><code>schedule()</code></a>, otherwise, tasks could monopolize a CPU, so an external component should intervene.</p><h3 id=nonvoluntary-preemption>Nonvoluntary: preemption<a hidden class=anchor aria-hidden=true href=#nonvoluntary-preemption>#</a></h3><p>As the main Linux scheduler class is a fair scheduler the fairness must be guaranteed in some way&mldr; Ok, but how does it preempt?</p><p>For this purpose, a flag named <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/include/asm/thread_info.h#L83><code>need_reschedule</code></a> is present in the <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/sched.h#L734><code>task_struct</code></a>&rsquo;s <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/include/asm/thread_info.h#L57><code>thread_info</code> flags (i.e. x86)</a> and is set or unset on the current task to notify that it should leave the CPU which in turn, after <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6377><code>schedule()</code></a> call, will switch to another process context.</p><p>So, when this flag is set?</p><ul><li>in <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L5250><code>scheduler_tick()</code></a>, which is constantly called by the timer interrupt <a href=https://elixir.bootlin.com/linux/v2.6.39/source/kernel/time/tick-common.c#L63>handler</a> (the architecture-independent part actually), continuously checking and updating <code>vruntime</code>, balancing the runqueues, it <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/fair.c#L4600>sets the flag</a> when preemption is needed.</li><li>in <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3985><code>try_to_wake_up()</code></a>, when the current task <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L3562>has minor priority</a> than the awakened.</li></ul><p>Then, in order to understand when the flag is checked, we can think about when a task preemption is needed and also can be done safely.</p><h5 id=in-userspace>In userspace<a hidden class=anchor aria-hidden=true href=#in-userspace>#</a></h5><p>Returning <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/entry-common.h#L301>from kernelspace to userspace</a> is safe to context switch: if it is safe to switch mode and continue executing the
current task, it is also safe to pick a new task to execute. Has this userspace task still to run? Maybe it’s no longer fair to run it. This is what happens when from:</p><ul><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/entry-common.h#L336>system calls</a></li><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/entry-common.h#L380>interrupt handlers</a></li></ul><p>return to userspace.</p><p><a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6459>If <code>need_resched</code> is set</a> a schedule is needed, the next entity task is picked, and context switch done.</p><blockquote><p>As a note, consider that both these paths are architecture-dependent, and typically implemented in assembly in entry.S (e.g. <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/entry/entry_64.S>x86_64</a>) which, aside from kernel entry code, also contains kernel exit code).</p></blockquote><h5 id=in-kernel-space>In kernel space<a hidden class=anchor aria-hidden=true href=#in-kernel-space>#</a></h5><p>A note deserves to be explained. The kernel is fully <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/Kconfig.preempt#L51>preemptive</a> from <a href=https://elixir.bootlin.com/linux/v2.6.0/source/arch/x86_64/Kconfig#L189>2.6</a> that is, a task can be preempted as long as the kernel is in a safe state.
When preemption can’t be done, locks are in place to mark it, so that a safe state is defined when the kernel doesn’t hold a lock.
Basically, a lock counter <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/arm64/include/asm/thread_info.h#L30><code>preempt_count</code></a> is added to <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/include/asm/thread_info.h#L57><code>thread_info</code> flags (x86)</a> to let preempt tasks that are running in kernelspace only when it’s equal to zero.</p><p>Upon return from interrupt to kernelspace or from process context during <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6493>preemption</a>, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6485>if <code>need_resched</code> is set</a> and <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6501><code>preempt_count</code> == 0</a> the current task is preempted, otherwise the interrupt returns to the interrupted task.</p><p>Also, every time <code>preempt_count</code> is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/preempt.h#L221>updated and decreased to zero and <code>need_resched</code> is true</a>, <a href=https://elixir.bootlin.com/linux/v5.17.9/source/include/linux/preempt.h#L222>preemption is done</a>.</p><p>For example, considering the return path from interrupt which is architecture-dependent, the <em>xtensa</em> ISA&rsquo;s common <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/xtensa/kernel/entry.S#L488>exception exit path</a> is pretty self-explanatory:</p><pre><code>common_exception_return:

	...

#ifdef CONFIG_PREEMPTION
6:
	_bbci.la4, TIF_NEED_RESCHED, 4f

	/* Check current_thread_info-&gt;preempt_count */

	l32ia4, a2, TI_PRE_COUNT
	bneza4, 4f
	abi_callpreempt_schedule_irq
	j4f
#endif
	...
</code></pre><blockquote><p>TL;DR About what we said above, you can check the <code>__schedule()</code> function <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/sched/core.c#L6151>comments</a>.</p></blockquote><p>Moreover, the kernel is <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/arm64/Kconfig#L312>SMP-safe</a> that is, a task can be safely restored in a symmetrical multi-processor.</p><p>You can check both <a href=https://elixir.bootlin.com/linux/v5.17.9/source/kernel/Kconfig.preempt#L51>preemption config</a> and <a href=https://elixir.bootlin.com/linux/v5.17.9/source/arch/x86/Kconfig#L400>SMP config (x86)</a> in your running kernel version from procfs:</p><pre><code>$ zcat /proc/config.gz | grep &quot;CONFIG_SMP\|CONFIG_PREEMPT&quot; | grep -v &quot;^#&quot;
CONFIG_PREEMPT_BUILD=y
CONFIG_PREEMPT=y
CONFIG_PREEMPT_COUNT=y
CONFIG_PREEMPTION=y
CONFIG_PREEMPT_DYNAMIC=y
CONFIG_PREEMPT_RCU=y
CONFIG_SMP=y
CONFIG_PREEMPT_NOTIFIERS=y
</code></pre><p>That’s all folks! We&rsquo;ve arrived to the end of this little journey.</p><hr><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><blockquote><p>The linked code refers to Linux 5.17.9.</p></blockquote><p>I liked the idea to leave you the choice to dig into each single path the kernel does to manage the tasks scheduling. That&rsquo;s why I intentionally didn&rsquo;t include so many snippets, instead providing you the code face of the coin for almost every path we saw, through links to the real Linux code.</p><p>What is incredible is that, even if it&rsquo;s one of the largest OSS projects, you can understand how Linux works and also contribute. That&rsquo;s why I love open source more every day!</p><h1 id=thank-you>Thank you!<a hidden class=anchor aria-hidden=true href=#thank-you>#</a></h1><p>I hope this was interesting for you as it was for me. Please, feel free to reach out!</p><ul><li><a href=https://twitter.com/maxgio92>twitter</a></li><li><a href=https://github.com/maxgio92>github</a></li><li><a href=https://www.linkedin.com/in/massimilianogiovagnoli>linkedin</a></li></ul><h1 id=links>Links<a hidden class=anchor aria-hidden=true href=#links>#</a></h1><ul><li><a href=https://www.kernel.org/doc/html/v5.17/scheduler/index.html>https://www.kernel.org/doc/html/v5.17/scheduler/index.html</a></li><li><a href=https://elixir.bootlin.com/linux/v5.17.9/source>https://elixir.bootlin.com/linux/v5.17.9/source</a></li><li><a href=https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468>https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468</a></li><li><a href=https://mechpen.github.io/posts/2020-04-27-cfs-group/index.html#2.2.-data-structures>https://mechpen.github.io/posts/2020-04-27-cfs-group/index.html#2.2.-data-structures</a></li><li><a href=https://josefbacik.github.io/kernel/scheduler/2017/07/14/scheduler-basics.html>https://josefbacik.github.io/kernel/scheduler/2017/07/14/scheduler-basics.html</a></li><li><a href=https://opensource.com/article/19/2/fair-scheduling-linux>https://opensource.com/article/19/2/fair-scheduling-linux</a></li><li><a href=https://lwn.net/Articles/531853/>https://lwn.net/Articles/531853/</a></li><li><a href=https://oska874.gitbooks.io/process-scheduling-in-linux/content/>https://oska874.gitbooks.io/process-scheduling-in-linux/content/</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://maxgio92.github.io/tags/linux/>linux</a></li><li><a href=http://maxgio92.github.io/tags/scheduler/>scheduler</a></li></ul><nav class=paginav><a class=next href=http://maxgio92.github.io/posts/stride-threat-modeling-kubernetes-elevation-of-privileges/><span class=title>Next »</span><br><span>STRIDE threat modeling on Kubernetes pt.6/6: Elevation of privilege</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share A journey into the Linux scheduler on twitter" href="https://twitter.com/intent/tweet/?text=A%20journey%20into%20the%20Linux%20scheduler&url=http%3a%2f%2fmaxgio92.github.io%2fposts%2flinux-scheduler-journey%2f&hashtags=linux%2cscheduler"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A journey into the Linux scheduler on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=http%3a%2f%2fmaxgio92.github.io%2fposts%2flinux-scheduler-journey%2f&title=A%20journey%20into%20the%20Linux%20scheduler&summary=A%20journey%20into%20the%20Linux%20scheduler&source=http%3a%2f%2fmaxgio92.github.io%2fposts%2flinux-scheduler-journey%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=http://maxgio92.github.io/>Maxgio's blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerHTML='copy';function copyingDone(){copybutton.innerHTML='copied!';setTimeout(()=>{copybutton.innerHTML='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>