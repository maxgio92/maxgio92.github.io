<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Unleashing the power of frame pointers for profilers pt.1 - The execution environment | Maxgio's blog</title><meta name=keywords content="profiling,optimization,ebpf"><meta name=description content="Profiling the CPU allows us to analyze the program&rsquo;s performance, identify bottlenecks, and optimize its efficiency.
Have you ever wondered what happens behind the scenes when you run a program and how to account for CPU time for the actual program functions? And even more, how to write such a tool to profile the program?
Even though great open-source projects provide continuous profiling with vast support for compiled, JITed, and interpreted, languages, with or without debug info, with or without frame pointers, etc."><meta name=author content><link rel=canonical href=https://blog.maxgio.me/posts/unleashing-power-frame-poiners-execution-environment/><link crossorigin=anonymous href=/assets/css/stylesheet.min.149ea7cdaa83f0ab31471ced9e0495af0272de908dd4a38e5c229d8b0579a758.css integrity="sha256-FJ6nzaqD8KsxRxztngSVrwJy3pCN1KOOXCKdiwV5p1g=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://blog.maxgio.me/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.maxgio.me/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.maxgio.me/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.maxgio.me/apple-touch-icon.png><link rel=mask-icon href=https://blog.maxgio.me/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','G-7DN0LVS78Q','auto');ga('send','pageview');}</script><meta property="og:title" content="Unleashing the power of frame pointers for profilers pt.1 - The execution environment"><meta property="og:description" content="Profiling the CPU allows us to analyze the program&rsquo;s performance, identify bottlenecks, and optimize its efficiency.
Have you ever wondered what happens behind the scenes when you run a program and how to account for CPU time for the actual program functions? And even more, how to write such a tool to profile the program?
Even though great open-source projects provide continuous profiling with vast support for compiled, JITed, and interpreted, languages, with or without debug info, with or without frame pointers, etc."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.maxgio.me/posts/unleashing-power-frame-poiners-execution-environment/"><meta property="og:image" content="https://blog.maxgio.me/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-06-23T21:00:00+02:00"><meta property="article:modified_time" content="2024-06-23T21:00:00+02:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.maxgio.me/papermod-cover.png"><meta name=twitter:title content="Unleashing the power of frame pointers for profilers pt.1 - The execution environment"><meta name=twitter:description content="Profiling the CPU allows us to analyze the program&rsquo;s performance, identify bottlenecks, and optimize its efficiency.
Have you ever wondered what happens behind the scenes when you run a program and how to account for CPU time for the actual program functions? And even more, how to write such a tool to profile the program?
Even though great open-source projects provide continuous profiling with vast support for compiled, JITed, and interpreted, languages, with or without debug info, with or without frame pointers, etc."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.maxgio.me/posts/"},{"@type":"ListItem","position":2,"name":"Unleashing the power of frame pointers for profilers pt.1 - The execution environment","item":"https://blog.maxgio.me/posts/unleashing-power-frame-poiners-execution-environment/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Unleashing the power of frame pointers for profilers pt.1 - The execution environment","name":"Unleashing the power of frame pointers for profilers pt.1 - The execution environment","description":"Profiling the CPU allows us to analyze the program\u0026rsquo;s performance, identify bottlenecks, and optimize its efficiency.\nHave you ever wondered what happens behind the scenes when you run a program and how to account for CPU time for the actual program functions? And even more, how to write such a tool to profile the program?\nEven though great open-source projects provide continuous profiling with vast support for compiled, JITed, and interpreted, languages, with or without debug info, with or without frame pointers, etc.","keywords":["profiling","optimization","ebpf"],"articleBody":"Profiling the CPU allows us to analyze the program’s performance, identify bottlenecks, and optimize its efficiency.\nHave you ever wondered what happens behind the scenes when you run a program and how to account for CPU time for the actual program functions? And even more, how to write such a tool to profile the program?\nEven though great open-source projects provide continuous profiling with vast support for compiled, JITed, and interpreted, languages, with or without debug info, with or without frame pointers, etc., don’t be discouraged!\nWriting your own can be a fantastic learning experience. Building your own profiler offers a unique challenge and the satisfaction of unlocking powerful performance analysis tools.\nThis blog series will embark on a journey to give you the basics for writing a program profiler.\nIn this first episode, we’ll establish the foundation by exploring the program execution environment. We’ll dig into how the CPU executes a program and keeps track of the execution flow. Finally, we’ll discover how this tracking data is stored and becomes the key to unlocking the profiling primitives.\nIntroduction We know that the CPU executes the programs and that the program’s binary instructions are stored in a volatile memory which is the random access memory.\nAs RAM locations are byte-addressable the CPU needs a way to keep track of the addresses in order to retrieve the data from it, which is in our case CPU instructions that are then executed.\nThe CPU uses small built-in memory areas called registers to hold data retrieved from the main memory. Registers come in two types: general-purpose and special-purpose. Special-purpose registers include pointer registers, which are designed specifically to store pointers, which means, they store the memory address’s value.\nThere are other types of registers but they’re out of scope for this walkthrough.\nThe first part will go through the main pointer registers, which are commonly implemented by the predominant architectures (x86, ARM, MIPS, PowerPC as far as I know). So, please consider that these specifics may differ depending on the architecture.\nThe good, the bad and the ugly pointer registers The program counter The program counter (PC), often also called instruction pointer (IP) in x86 architectures, is a register that points to code, that is, the instruction that will be executed next. The instruction data will be fetched, will be stored in the instruction register (IR), and executed during the instruction cycle. You can follow a diagram of a simplified instruction cycle in the picture below:\n The CPU control unit (CU) read the value of the PC It sends it to the CPU Memory Unit (MU) The MU reads the instruction code from the memory at the address pointed to by the PC The MU stores the opcode to the IR The MU reads the opcode The MU sends the opcode to the CU The CU instructs the Register File (RF) to read operands - if available from registers, I’m simplifying - from general purpose registers (GPR) The RF reads operands from GPRs The CU sends them to the Arithmetic Logic Unit (ALU), which calculates and stores the result in its temporary memory The CU requests the ALU to perform the arithmetic and logic operations The RF reads the result from the ALU The RF stores the AL result in GPRs  For example, considering a CALL instruction, this could be the flow considering the PC, the IR and the mainly involved general purpose registers to store the operands:\nDepending on the instruction set, the PC will be increased instruction by instruction by the instruction size (e.g. 8 bytes on 64 but Instruction Set Architectures).\nIn an executable file, the machine code to be executed by the CPU is usually stored in a dedicated section, depending on the executable format. For example, in ELF (Executable and Linkable Format) the machine code is organized in the .text section.\nThe stack pointer On the other side, the stack pointer (SP) and base pointer (BP) point to the stack, which contains data about the program being executed.\nWhile a detailed explanation of the stack is beyond the scope of this blog, here’s a basic idea: it’s a special area of memory that the CPU uses to manage data related to the program’s functions (subroutines) as they are called and executed, pushing it to it in a LIFO method. We’ll see later on in more detail.\nData and code are organized in specific regions inside the process address space. It’s constantly updated by the CPU on push and pop operations on the stack. The stack pointer is usually set by the OS during the load to point to the top of the stack memory region.\nAs the stack grows whenever the CPU adds new data while executing the program’s instructions, the stack pointer decrements and is always at the lowest position in the stack.\n Remember: the stack grows from the highest address to the lowest address:\n So, when a new variable of 4 bytes is declared, the stack pointer will be decreased by 4 bytes too.\nFor instance, considering a C function that declare a local variable:\nvoid myFunction() { int localVar = 10; // Local variable declaration  // Use localVar here } the simplified resulting machine code could be something like the following:\n; Allocate space for local variables (assuming 4 bytes for integer) sub rsp, 4 ; Subtract 4 from stack pointer (SP) to reserve space ; Move value 10 (in binary) to localVar's memory location mov dword ptr [rsp], 10 ; Move 10 (dword = 4 bytes) to memory pointed to by SP (stack top) ; ... ; Function cleanup (potential instruction to restore stack space) add rsp, 4 ; Add 4 back to stack pointer to deallocate local variable space  Clarification about the register names\nYou’ll find different names for these pointer registers depending on the architectures. For example for x86:\n On 16-bit architecture are usually called sp, bp, and ip. Instead on 32-bit esp, ebp, and eip. Finally, on 64-bit they’re usually called rsp, rbp, and rip.   Specifically, a stack pointer (SP) points to the first free and unused address on the stack. It can reserve more space on the stack by adjusting the stack pointer like in the previous code example.\nAs a detail, a more concise way could be to use push that combines the decrement of the SP (i.e. by 4 bytes) and the store of the operand (i.e. the integer 10) at the new address pointed to by the SP.\nThe base pointer The base pointer (BP) is set during function calls by copying the current SP. The BP is a snapshot of the SP at the moment of the function call (e.g. when the CPU fetches a call instruction), so that function parameters and local variables are accessed by adding and subtracting, respectively, a constant offset from it.\nMoreover when a new function is called a new space in the stack dedicated to the new function is created and some data like declaration of local variables is pushed.\nThis memory space dedicated to these subroutines are the stack frames, so each function will have a stack frame. You can find a simple scheme of stack frames with the main data pushed to the stack in the picture below:\nPlease bear in mind that the stack layout can vary based on the ABI calling convention and the architecture.\nWe’ll now go through the call path and see which data is also pushed to the stack, which is used to keep track of the execution path.\nThe call path When a new function is called the previous base pointer (BP) is also pushed to the new stack frame.\nWhile this is usually true, it’s not mandatory and it depends on how the binary has been compiled. This mainly depends on the compiler optimization techniques.\nIn particular, CALL instruction pushes also the value of the program counter at the moment of the new function call (next instruction address), and gives control to the target address. The program counter is set to the target address of the CALL instruction, which is, the first instruction of the called function.\nIn a nutshell: the just pushed return address is a snapshot of the program counter, and the pushed frame pointer is a snapshot of the base pointer, and they’re both available in the stack.\nAs a result, control is passed to the called subroutine address and the return address, that is the address of the instruction next to CALL, is available on the stack.\nThe following diagram wrap ups what’s been discussed until now:\nThe return path On the return path from the function, RET instruction POPs the return address from the stack and puts it in the program counter register. So, the next instruction is available from that return address.\nSince the program counter register holds the address of the next instruction to be executed, loading the return address into the PC effectively points the program execution to the instruction that follows the function call. This ensures the program resumes execution from the correct location after the function is completed.\n Credits for the diagram to the Learn WinDbg website.\n In the case of a function calling a function, the program counter returns to the return address in the previous stack frame and starts executing from there.\nBecause all of the above points need to be memorized on the stack, the stack size will naturally increase, and on return decrease. And of course, the same happens to the stack and base pointers. Naturally, the stack is protected by a guard to avoid the stack overflow accessing unexpected area of memory.\nAs I’m a visual learner, the next section will show how the program’s code and data are organized in its process address space. This should give you a clearer picture of their layout within the process’s address space.\nThe address space regions The process address space is a logical view of memory managed by the operating system, hiding the complexity of managing physical memory.\nWhile explaining how memory mapping implementations work in operating systems is out of scope here, it’s important to say that user processes see one contiguous memory space thanks to the memory mapping features provided by the OS.\nThe address space is typically divided into different regions, and the following names are mostly standard between the operating systems:\n Text segment: this is the area where the (machine) code of the program is stored Data segment: this region contains typically static variables which are initialized BSS (Block Started by Symbol) segment: it contains global and static variables that are not initialized when the program starts. Because the data would be a block of zeros, the BSS content is omitted in the executable file, saving space. Instead, the program headers allow the loader to know how much space to allocate for the BSS section in virtual memory and it filled it out with zeros. That’s why, despite uninitialized data being data, is not placed in the data section. Heap: it’s a region available for dynamic allocation available to the running process. Programs can request pages from it at runtime (e.g. malloc from the C standard library). Stack: we already talked about it.  The next diagram will show the discussed memory regions starting from the physical perspective to the perspective of the single virtual address space of a program process:\n Credits for the diagram to yousha.blog.ir.\n The operating system can enforce protection for each of them, like marking the text section read-only to prevent modification of the running program’s instructions.\nWhen a program is loaded into memory, the operating system allocates a specific amount of memory for it and dedicates specific regions to static and dynamic allocation. The static allocation includes the allocation for the program’s instructions and the stack.\nDynamic allocations can be handled by the stack or the heap. The heap usually acquires memory from the bottom of the same region and grows upwards towards the middle of the same memory region.\nProgram loading in Unix-like OSes On program execution (Unix-like fork and exec system call groups) OS allocates memory to later store the program’s code and data. The exec family of system calls replaces the program executed by a process. When a process calls exec, all sections are replaced, including the .text section, and the data in the process are replaced with the executable of the new program.\nIn particular, the loader parses the executable file, decides which is the base address, allocates memory for the program segments based on the base address, loads the segments in memory, and prepares the execution environment.\nOnce the loader completes its tasks, it signals the kernel the program is ready. The kernel sets the process context and the PC to the first instruction in the .text section, which is fetched, decoded, and executed by the CPU.\n Credits for the diagram to the Uppsala University. I haven’t managed yet to find where the information about how to set up the stack at exec time from an ELF file is stored in the ELF structure. If you do, feel free to share it!\n Moreover, as a detail, although all data is replaced, all open file descriptors remain open after calling exec unless explicitly set to close-on-exec.\nIf you want to go deeper on the Linux exec path, I recommend this chapter from the Linux insides book.\nNow let’s get back to the main characters of this blog, which are the pointer register. We mentioned that the base pointer is also called the frame pointer, indeed it points to a single stack frame. But, let’s see how they’re vital for CPU profiling.\nFrame pointer and the stack walking I’ve read more often the name frame pointer than base pointer, but actually the frame pointer is the base pointer.\nAs already discussed, the name base pointer comes to the fact that is set up when a function is called and is pushed to the new stack frame, to establish a fixed reference (base) to access local variables and parameters within the function’s stack frame.\nWhat is pushed to the stack are also the parameters, but depending on the ABI, they can be passed either on the stack or via registers. For instance:\n x86-64 System V ABI: in the general purpose registers rdi, rsi, rdx, rcx, r8, and r9 for the first six parameters. On the stack from the seventh parameter onward. i386 System V ABI: in the general purpose registers eax, ecx, edx, and ebx for the first four parameters. On the stack from the fifth parameter onward.  In general, the data that is commonly stored on the stack is:\n the return address the previous frame pointer saved register state the local variables of the function.   Remember: the return address is a snapshot of the program counter, so it points to instructions (code). The previous frame pointer is a snapshot of the base pointer, so it points to the stack (data).\n Below the local variables are other stack frames resulting from more recent function calls, as well as generic stack space used for computation and temporary storage. The most recent of these is pointed to by the stack pointer. This is the difference between the stack pointer and the frame/base pointer.\nHowever, the frame pointer is not always required. Compiler optimization technique can generate code that just uses the stack pointer.\nFrame pointer elimination (FPE) is an optimization that removes the need for a frame pointer under certain conditions, mainly to reduce the space allocated for the stack and to optimize performance because pushing and popping the frame pointer takes time during the function call. The compiler analyzes the function’s code to see if it relies on the frame pointer for example to access local variables, or if the function does not call any other function. At any point in code generation, it can determine where the return address, parameters, and locals are relative to the stack pointer address (either by a constant offset or programmatically).\nFrame pointer omission (FPO) is instead an optimization that simply instructs the compiler to not generate instructions to push and pop the frame pointer at all during function calls and returns.\n If you’re interested in the impacts of libraries compiled and distributed with this optimization I recommend the following Brendan Gregg’s great article: The Return of the Frame Pointers.\n Because the frame pointer is pushed on function call to the stack frame just created for the newly called function, and its value is the value of the stack pointer at the moment of the CALL, it points to the previous stack frame.\nA fundmental data needed by CPU profilers is to build stack traces, to understand the execution flow of a program and calculate the time spent for each trace and function.\nOne standard technique to build a stack trace is by walking fhe stack. And one technique to walk the stack is to follow the linked list of the saved frame pointers, beginning with the value hold by the base pointer register.\nBecause a RET (function returns) pops a stack frame out of the stack, when consequent RETs reach the top of the stack, which is the stack frame of the main function, a stack trace is complete. The same goes on and on with subsequent chains of call-returns that reach the top of the stack.\nYou can see it in the following picture a simplified scheme of the linked list of frame pointers:\n I didn’t manage to find the author of this diagram. If you do, please let me know so that I can give the right credits, thank you.\n This technique is particularly useful for profilers and debuggers. The following is a basic example of what a profiler could retrieve, leveraging frame pointers:\n$ ./my-profiler run --pid 12345 2.6% main.main;runtime.main;runtime.goexit; 65.3% main.foo;runtime.main;runtime.goexit; 32.1% main.bar;runtime.main;runtime.goexit; And this comes to the next episode of this series, which will dive into how to write a basic low-overhead, kernel-assisted CPU profiler leveraging eBPF, that will produce a result like the one above!\nI hope this has been interesting to you. Any feedback is more than appreciated.\nSee you in the next episode!\n","wordCount":"3029","inLanguage":"en","datePublished":"2024-06-23T21:00:00+02:00","dateModified":"2024-06-23T21:00:00+02:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.maxgio.me/posts/unleashing-power-frame-poiners-execution-environment/"},"publisher":{"@type":"Organization","name":"Maxgio's blog","logo":{"@type":"ImageObject","url":"https://blog.maxgio.me/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://blog.maxgio.me/ accesskey=h title="Maxgio's blog (Alt + H)">Maxgio's blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://blog.maxgio.me/posts title=Posts><span>Posts</span></a></li><li><a href=https://blog.maxgio.me/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://blog.maxgio.me/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://github.com/maxgio92 title=Github><span>Github</span></a></li><li><a href=https://hachyderm.io/@maxgio92 title=Mastodon><span>Mastodon</span></a></li><li><a href=https://twitter.com/maxgio92 title=Twitter><span>Twitter</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.maxgio.me/>Home</a>&nbsp;»&nbsp;<a href=https://blog.maxgio.me/posts/>Posts</a></div><h1 class=post-title>Unleashing the power of frame pointers for profilers pt.1 - The execution environment</h1><div class=post-meta><span title="2024-06-23 21:00:00 +0200 +0200">June 23, 2024</span>&nbsp;·&nbsp;15 min</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#the-good-the-bad-and-the-ugly-pointer-registers aria-label="The good, the bad and the ugly pointer registers">The good, the bad and the ugly pointer registers</a><ul><li><a href=#the-program-counter aria-label="The program counter">The program counter</a></li><li><a href=#the-stack-pointer aria-label="The stack pointer">The stack pointer</a></li><li><a href=#the-base-pointer aria-label="The base pointer">The base pointer</a></li></ul></li><li><a href=#the-call-path aria-label="The call path">The call path</a></li><li><a href=#the-return-path aria-label="The return path">The return path</a></li><li><a href=#the-address-space-regions aria-label="The address space regions">The address space regions</a></li><li><a href=#program-loading-in-unix-like-oses aria-label="Program loading in Unix-like OSes">Program loading in Unix-like OSes</a></li><li><a href=#frame-pointer-and-the-stack-walking aria-label="Frame pointer and the stack walking">Frame pointer and the stack walking</a></li></ul></div></details></div><div class=post-content><p>Profiling the CPU allows us to analyze the program&rsquo;s performance, identify bottlenecks, and optimize its efficiency.</p><p>Have you ever wondered what happens behind the scenes when you run a program and how to account for CPU time for the actual program functions? And even more, how to write such a tool to profile the program?</p><p>Even though great open-source projects provide continuous profiling with vast support for compiled, JITed, and interpreted, languages, with or without debug info, with or without frame pointers, etc., don&rsquo;t be discouraged!</p><p>Writing your own can be a fantastic learning experience. Building your own profiler offers a unique challenge and the satisfaction of unlocking powerful performance analysis tools.</p><p>This blog series will embark on a journey to give you the basics for writing a program profiler.</p><p>In this first episode, we&rsquo;ll establish the foundation by exploring the program execution environment. We&rsquo;ll dig into how the CPU executes a program and keeps track of the execution flow. Finally, we&rsquo;ll discover how this tracking data is stored and becomes the key to unlocking the profiling primitives.</p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>We know that the CPU executes the programs and that the program&rsquo;s binary instructions are stored in a volatile memory which is the random access memory.</p><p>As RAM locations are byte-addressable the CPU needs a way to keep track of the addresses in order to retrieve the data from it, which is in our case CPU instructions that are then executed.</p><p>The CPU uses small built-in memory areas called registers to hold data retrieved from the main memory. Registers come in two types: general-purpose and special-purpose. Special-purpose registers include pointer registers, which are designed specifically to store pointers, which means, they store the memory address&rsquo;s value.</p><p>There are other types of registers but they&rsquo;re out of scope for this walkthrough.</p><p>The first part will go through the main pointer registers, which are commonly implemented by the predominant architectures (x86, ARM, MIPS, PowerPC as far as I know).
So, please consider that these specifics may differ depending on the architecture.</p><h2 id=the-good-the-bad-and-the-ugly-pointer-registers>The good, the bad and the ugly pointer registers<a hidden class=anchor aria-hidden=true href=#the-good-the-bad-and-the-ugly-pointer-registers>#</a></h2><h3 id=the-program-counter>The program counter<a hidden class=anchor aria-hidden=true href=#the-program-counter>#</a></h3><p>The program counter (PC), often also called instruction pointer (IP) in x86 architectures, is a register that points to code, that is, the instruction that will be executed next. The instruction data will be fetched, will be stored in the instruction register (IR), and executed during the instruction cycle.
You can follow a diagram of a simplified instruction cycle in the picture below:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/b76dfca9825c61c9d1d02c0eddf0b4619869185d/content/images/cpu-pc-ir-cycle.svg alt=cpu-pc-ir></p><ol><li>The CPU control unit (CU) read the value of the PC</li><li>It sends it to the CPU Memory Unit (MU)</li><li>The MU reads the instruction code from the memory at the address pointed to by the PC</li><li>The MU stores the opcode to the IR</li><li>The MU reads the opcode</li><li>The MU sends the opcode to the CU</li><li>The CU instructs the Register File (RF) to read operands - if available from registers, I&rsquo;m simplifying - from general purpose registers (GPR)</li><li>The RF reads operands from GPRs</li><li>The CU sends them to the Arithmetic Logic Unit (ALU), which calculates and stores the result in its temporary memory</li><li>The CU requests the ALU to perform the arithmetic and logic operations</li><li>The RF reads the result from the ALU</li><li>The RF stores the AL result in GPRs</li></ol><p>For example, considering a <code>CALL</code> instruction, this could be the flow considering the PC, the IR and the mainly involved general purpose registers to store the operands:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/4979fc04a3da60187ea4e3175dfa8966abdf0fc6/content/images/cpu-pc-ir-cycle-2.svg alt=cpu-pc-ir-call></p><p>Depending on the instruction set, the PC will be increased instruction by instruction by the instruction size (e.g. 8 bytes on 64 but Instruction Set Architectures).</p><p>In an executable file, the machine code to be executed by the CPU is usually stored in a dedicated section, depending on the executable format. For example, in ELF (Executable and Linkable Format) the machine code is organized in the <code>.text</code> section.</p><h3 id=the-stack-pointer>The stack pointer<a hidden class=anchor aria-hidden=true href=#the-stack-pointer>#</a></h3><p>On the other side, the stack pointer (SP) and base pointer (BP) point to the stack, which contains data about the program being executed.</p><p>While a detailed explanation of the stack is beyond the scope of this blog, here&rsquo;s a basic idea: it&rsquo;s a special area of memory that the CPU uses to manage data related to the program&rsquo;s functions (subroutines) as they are called and executed, pushing it to it in a LIFO method. We&rsquo;ll see later on in more detail.</p><p>Data and code are organized in specific regions inside the process address space. It&rsquo;s constantly updated by the CPU on push and pop operations on the stack. The stack pointer is usually set by the OS during the load to point to the top of the stack memory region.</p><p>As the stack grows whenever the CPU adds new data while executing the program&rsquo;s instructions, the stack pointer decrements and is always at the lowest position in the stack.</p><blockquote><p>Remember: the stack grows from the highest address to the lowest address:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/faf4b0c39f4a1e2e84a3bb497729fa5863aed5ed/content/images/mem-stack-code-heap.svg alt=mem-stack-code-heap></p></blockquote><p>So, when a new variable of 4 bytes is declared, the stack pointer will be decreased by 4 bytes too.</p><p>For instance, considering a C function that declare a local variable:</p><div class=highlight><pre class=chroma><code class=language-c data-lang=c><span class=kt>void</span> <span class=nf>myFunction</span><span class=p>()</span> <span class=p>{</span>
  <span class=kt>int</span> <span class=n>localVar</span> <span class=o>=</span> <span class=mi>10</span><span class=p>;</span> <span class=c1>// Local variable declaration
</span><span class=c1></span>  <span class=c1>// Use localVar here
</span><span class=c1></span><span class=p>}</span>
</code></pre></div><p>the simplified resulting machine code could be something like the following:</p><pre><code class=language-assembly data-lang=assembly>; Allocate space for local variables (assuming 4 bytes for integer)
sub  rsp, 4               ; Subtract 4 from stack pointer (SP) to reserve space

; Move value 10 (in binary) to localVar's memory location
mov  dword ptr [rsp], 10  ; Move 10 (dword = 4 bytes) to memory pointed to by SP (stack top)

; ...

; Function cleanup (potential instruction to restore stack space)
add  rsp, 4              ; Add 4 back to stack pointer to deallocate local variable space
</code></pre><blockquote><p><strong>Clarification about the register names</strong></p><p>You&rsquo;ll find different names for these pointer registers depending on the architectures. For example for x86:</p><ul><li>On 16-bit architecture are usually called <code>sp</code>, <code>bp</code>, and <code>ip</code>.</li><li>Instead on 32-bit <code>esp</code>, <code>ebp</code>, and <code>eip</code>.</li><li>Finally, on 64-bit they&rsquo;re usually called <code>rsp</code>, <code>rbp</code>, and <code>rip</code>.</li></ul></blockquote><p>Specifically, a stack pointer (SP) points to the first free and unused address on the stack.
It can reserve more space on the stack by adjusting the stack pointer like in the previous code example.</p><p>As a detail, a more concise way could be to use <code>push</code> that combines the decrement of the SP (i.e. by 4 bytes) and the store of the operand (i.e. the integer <code>10</code>) at the new address pointed to by the SP.</p><h3 id=the-base-pointer>The base pointer<a hidden class=anchor aria-hidden=true href=#the-base-pointer>#</a></h3><p>The base pointer (BP) is set during function calls by copying the current SP. The BP is a snapshot of the SP at the moment of the function call (e.g. when the CPU fetches a <code>call</code> instruction), so that function parameters and local variables are accessed by adding and subtracting, respectively, a constant offset from it.</p><p>Moreover when a new function is called a new space in the stack dedicated to the new function is created and some data like declaration of local variables is pushed.</p><p>This memory space dedicated to these subroutines are the stack frames, so each function will have a stack frame. You can find a simple scheme of stack frames with the main data pushed to the stack in the picture below:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/99171626abe0c24cf00a66c480287d4701ec61df/content/images/memory-sp-bp.svg alt=memory-sp-bp></p><p>Please bear in mind that the stack layout can vary based on the ABI calling convention and the architecture.</p><p>We&rsquo;ll now go through the call path and see which data is also pushed to the stack, which is used to keep track of the execution path.</p><h2 id=the-call-path>The call path<a hidden class=anchor aria-hidden=true href=#the-call-path>#</a></h2><p>When a new function is called the previous base pointer (BP) is also pushed to the new stack frame.</p><p>While this is usually true, it&rsquo;s not mandatory and it depends on how the binary has been compiled. This mainly depends on the compiler optimization techniques.</p><p>In particular, CALL instruction pushes also the value of the program counter at the moment of the new function call (next instruction address), and gives control to the target address. The program counter is set to the target address of the <code>CALL</code> instruction, which is, the first instruction of the called function.</p><p>In a nutshell: the just pushed return address is a snapshot of the program counter, and the pushed frame pointer is a snapshot of the base pointer, and they&rsquo;re both available in the stack.</p><p>As a result, control is passed to the called subroutine address and the return address, that is the address of the instruction next to <code>CALL</code>, is available on the stack.</p><p>The following diagram wrap ups what&rsquo;s been discussed until now:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/352907a2c42b9f695d0a97e6cd8d3e95977d024d/content/images/pc-sp-bc-stack-code.svg alt=pc-sp-bc-stack-code></p><h2 id=the-return-path>The return path<a hidden class=anchor aria-hidden=true href=#the-return-path>#</a></h2><p>On the return path from the function, <code>RET</code> instruction <code>POP</code>s the return address from the stack and puts it in the program counter register. So, the next instruction is available from that return address.</p><p>Since the program counter register holds the address of the next instruction to be executed, loading the return address into the PC effectively points the program execution to the instruction that follows the function call. This ensures the program resumes execution from the correct location after the function is completed.</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/14bdde325f646b53ee0b6501f0ba9d3ecbaded4f/content/notes/memory-stack-frames.png alt=stack-frames></p><blockquote><p>Credits for the diagram to the <a href=http://www.windbg.xyz/windbg/article/202-Typical-x86-call-stack-example>Learn WinDbg</a> website.</p></blockquote><p>In the case of a function calling a function, the program counter returns to the return address in the previous stack frame and starts executing from there.</p><p>Because all of the above points need to be memorized on the stack, the stack size will naturally increase, and on return decrease. And of course, the same happens to the stack and base pointers. Naturally, the stack is protected by a guard to avoid the stack overflow accessing unexpected area of memory.</p><p>As I&rsquo;m a visual learner, the next section will show how the program&rsquo;s code and data are organized in its process address space. This should give you a clearer picture of their layout within the process&rsquo;s address space.</p><h2 id=the-address-space-regions>The address space regions<a hidden class=anchor aria-hidden=true href=#the-address-space-regions>#</a></h2><p>The process address space is a logical view of memory managed by the operating system, hiding the complexity of managing physical memory.</p><p>While explaining how memory mapping implementations work in operating systems is out of scope here, it&rsquo;s important to say that user processes see one contiguous memory space thanks to the memory mapping features provided by the OS.</p><p>The address space is typically divided into different regions, and the following names are mostly standard between the operating systems:</p><ul><li>Text segment: this is the area where the (machine) code of the program is stored</li><li>Data segment: this region contains typically static variables which are initialized</li><li>BSS (Block Started by Symbol) segment: it contains global and static variables that are not initialized when the program starts.
Because the data would be a block of zeros, the BSS content is omitted in the executable file, saving space. Instead, the program headers allow the loader to know how much space to allocate for the BSS section in virtual memory and it filled it out with zeros. That&rsquo;s why, despite uninitialized data being data, is not placed in the data section.</li><li>Heap: it&rsquo;s a region available for dynamic allocation available to the running process. Programs can request pages from it at runtime (e.g. <code>malloc</code> from the C standard library).</li><li>Stack: we already talked about it.</li></ul><p>The next diagram will show the discussed memory regions starting from the physical perspective to the perspective of the single virtual address space of a program process:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/68c5220995702493845a3d96cc9d6dc7ce61ec8f/content/notes/memory-regions-allocations.jpg alt=memory-regions-stack-instructions></p><blockquote><p>Credits for the diagram to <a href=https://yousha.blog.ir/>yousha.blog.ir</a>.</p></blockquote><p>The operating system can enforce protection for each of them, like marking the text section read-only to prevent modification of the running program&rsquo;s instructions.</p><p>When a program is loaded into memory, the operating system allocates a specific amount of memory for it and dedicates specific regions to static and dynamic allocation. The static allocation includes the allocation for the program&rsquo;s instructions and the stack.</p><p>Dynamic allocations can be handled by the stack or the heap. The heap usually acquires memory from the bottom of the same region and grows upwards towards the middle of the same memory region.</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/b64ccd53d5c3a07969dd70f1a5a394c04edd8c35/content/images/memory-regions.svg alt=memory-regions></p><h2 id=program-loading-in-unix-like-oses>Program loading in Unix-like OSes<a hidden class=anchor aria-hidden=true href=#program-loading-in-unix-like-oses>#</a></h2><p>On program execution (Unix-like <code>fork</code> and <code>exec</code> system call groups) OS allocates memory to later store the program&rsquo;s code and data.
The <code>exec</code> family of system calls replaces the program executed by a process.
When a process calls <code>exec</code>, all sections are replaced, including the <code>.text</code> section, and the data in the process are replaced with the executable of the new program.</p><p>In particular, the loader parses the executable file, decides which is the base address, allocates memory for the program segments based on the base address, loads the segments in memory, and prepares the execution environment.</p><p>Once the loader completes its tasks, it signals the kernel the program is ready. The kernel sets the process context and the PC to the first instruction in the <code>.text</code> section, which is fetched, decoded, and executed by the CPU.</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/d3bf6f231c330ba746354cc463469245fc9de7bc/content/notes/memory-map-exec.png alt=memory-map-exec></p><blockquote><p>Credits for the diagram to the <a href=https://www2.it.uu.se/edu/course/homepage/os/vt19/module-2/exec/>Uppsala University</a>.
I haven&rsquo;t managed yet to find where the information about how to set up the stack at exec time from an ELF file is stored in the ELF structure. If you do, feel free to share it!</p></blockquote><p>Moreover, as a detail, although all data is replaced, all open file descriptors remain open after calling exec unless explicitly set to close-on-exec.</p><p>If you want to go deeper on the Linux <code>exec</code> path, I recommend <a href=https://github.com/0xAX/linux-insides/blob/f7c6b82a5c02309f066686dde697f4985645b3de/SysCall/linux-syscall-4.md#execve-system-call>this chapter</a> from the <a href=https://0xax.gitbooks.io/linux-insides/content/index.html>Linux insides</a> book.</p><p>Now let&rsquo;s get back to the main characters of this blog, which are the pointer register. We mentioned that the base pointer is also called the frame pointer, indeed it points to a single stack frame. But, let&rsquo;s see how they&rsquo;re vital for CPU profiling.</p><h2 id=frame-pointer-and-the-stack-walking>Frame pointer and the stack walking<a hidden class=anchor aria-hidden=true href=#frame-pointer-and-the-stack-walking>#</a></h2><p>I&rsquo;ve read more often the name <em>frame pointer</em> than <em>base pointer</em>, but actually the frame pointer <em>is</em> the base pointer.</p><p>As already discussed, the name base pointer comes to the fact that is set up when a function is called and is pushed to the new stack frame, to establish a fixed reference (base) to access local variables and parameters within the function&rsquo;s stack frame.</p><p>What is pushed to the stack are also the parameters, but depending on the ABI, they can be passed either on the stack or via registers. For instance:</p><ul><li>x86-64 System V ABI: in the general purpose registers <code>rdi</code>, <code>rsi</code>, <code>rdx</code>, <code>rcx</code>, <code>r8</code>, and <code>r9</code> for the first six parameters. On the stack from the seventh parameter onward.</li><li>i386 System V ABI: in the general purpose registers <code>eax</code>, <code>ecx</code>, <code>edx</code>, and <code>ebx</code> for the first four parameters. On the stack from the fifth parameter onward.</li></ul><p>In general, the data that is commonly stored on the stack is:</p><ul><li>the return address</li><li>the previous frame pointer</li><li>saved register state</li><li>the local variables of the function.</li></ul><p><img loading=lazy src=https://github.com/maxgio92/notes/raw/95038de4ae46e0b980cfbdbae35817132b3afffd/content/images/memory-sp-bp-3.svg alt=memory-sp-bp-3></p><blockquote><p>Remember: the return address is a snapshot of the program counter, so it points to instructions (code).
The previous frame pointer is a snapshot of the base pointer, so it points to the stack (data).</p></blockquote><p>Below the local variables are other stack frames resulting from more recent function calls, as well as generic stack space used for computation and temporary storage. The most recent of these is pointed to by the stack pointer. This is the difference between the stack pointer and the frame/base pointer.</p><p>However, the frame pointer is not always required. Compiler optimization technique can generate code that just uses the stack pointer.</p><p>Frame pointer elimination (FPE) is an optimization that removes the need for a frame pointer under certain conditions, mainly to reduce the space allocated for the stack and to optimize performance because pushing and popping the frame pointer takes time during the function call. The compiler analyzes the function&rsquo;s code to see if it relies on the frame pointer for example to access local variables, or if the function does not call any other function. At any point in code generation, it can determine where the return address, parameters, and locals are relative to the stack pointer address (either by a constant offset or programmatically).</p><p>Frame pointer omission (FPO) is instead an optimization that simply instructs the compiler to not generate instructions to push and pop the frame pointer at all during function calls and returns.</p><blockquote><p>If you&rsquo;re interested in the impacts of libraries compiled and distributed with this optimization I recommend the following Brendan Gregg&rsquo;s great article: <a href=https://www.brendangregg.com/blog/2024-03-17/the-return-of-the-frame-pointers.html>The Return of the Frame Pointers</a>.</p></blockquote><p>Because the frame pointer is pushed on function call to the stack frame just created for the newly called function, and its value is the value of the stack pointer at the moment of the <code>CALL</code>, it points to the previous stack frame.</p><p>A fundmental data needed by CPU profilers is to build stack traces, to understand the execution flow of a program and calculate the time spent for each trace and function.</p><p>One standard technique to build a stack trace is by walking fhe stack.
And one technique to walk the stack is to follow the linked list of the saved frame pointers, beginning with the value hold by the base pointer register.</p><p>Because a <code>RET</code> (function returns) pops a stack frame out of the stack, when consequent <code>RET</code>s reach the top of the stack, which is the stack frame of the main function, a stack trace is complete. The same goes on and on with subsequent chains of call-returns that reach the top of the stack.</p><p>You can see it in the following picture a simplified scheme of the linked list of frame pointers:</p><p><img loading=lazy src=https://raw.githubusercontent.com/maxgio92/notes/5eeff1703e85c00799e7af0117a3898918d7a438/content/notes/stack-walking.avif alt=stack-walking></p><blockquote><p>I didn&rsquo;t manage to find the author of this diagram. If you do, please let me know so that I can give the right credits, thank you.</p></blockquote><p>This technique is particularly useful for profilers and debuggers. The following is a basic example of what a profiler could retrieve, leveraging frame pointers:</p><div class=highlight><pre class=chroma><code class=language-shell data-lang=shell>$ ./my-profiler run --pid <span class=m>12345</span>
 2.6%     main.main<span class=p>;</span>runtime.main<span class=p>;</span>runtime.goexit<span class=p>;</span>
65.3%     main.foo<span class=p>;</span>runtime.main<span class=p>;</span>runtime.goexit<span class=p>;</span>
32.1%     main.bar<span class=p>;</span>runtime.main<span class=p>;</span>runtime.goexit<span class=p>;</span>
</code></pre></div><p>And this comes to the next episode of this series, which will dive into how to write a basic low-overhead, kernel-assisted CPU profiler leveraging eBPF, that will produce a result like the one above!</p><p>I hope this has been interesting to you. Any feedback is more than appreciated.</p><p>See you in the next episode!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.maxgio.me/tags/profiling/>profiling</a></li><li><a href=https://blog.maxgio.me/tags/optimization/>optimization</a></li><li><a href=https://blog.maxgio.me/tags/ebpf/>ebpf</a></li></ul><nav class=paginav><a class=next href=https://blog.maxgio.me/posts/improving-consistency-performance-go-crawler-retry-logics-http-client-tuning/><span class=title>Next »</span><br><span>How I improved consistency and performance in a Go crawler with retry logics and network tuning</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Unleashing the power of frame pointers for profilers pt.1 - The execution environment on twitter" href="https://twitter.com/intent/tweet/?text=Unleashing%20the%20power%20of%20frame%20pointers%20for%20profilers%20pt.1%20-%20The%20execution%20environment&url=https%3a%2f%2fblog.maxgio.me%2fposts%2funleashing-power-frame-poiners-execution-environment%2f&hashtags=profiling%2coptimization%2cebpf"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Unleashing the power of frame pointers for profilers pt.1 - The execution environment on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fblog.maxgio.me%2fposts%2funleashing-power-frame-poiners-execution-environment%2f&title=Unleashing%20the%20power%20of%20frame%20pointers%20for%20profilers%20pt.1%20-%20The%20execution%20environment&summary=Unleashing%20the%20power%20of%20frame%20pointers%20for%20profilers%20pt.1%20-%20The%20execution%20environment&source=https%3a%2f%2fblog.maxgio.me%2fposts%2funleashing-power-frame-poiners-execution-environment%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://blog.maxgio.me/>Maxgio's blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerHTML='copy';function copyingDone(){copybutton.innerHTML='copied!';setTimeout(()=>{copybutton.innerHTML='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>